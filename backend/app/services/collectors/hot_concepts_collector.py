"""
çƒ­é—¨æ¦‚å¿µæ¿å—æ•°æ®é‡‡é›†æœåŠ¡
æ”¯æŒå¤šæ•°æ®æºè‡ªåŠ¨é™çº§æœºåˆ¶

æ•°æ®æºä¼˜å…ˆçº§:
1. AKShare - åŒèŠ±é¡ºæ¦‚å¿µæ¿å— (stock_board_concept_name_ths) - å…è´¹ï¼Œæ•°æ®ä¸°å¯Œ
2. AKShare - ä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å— (stock_board_concept_name_em) - å…è´¹ï¼Œå®æ—¶æ€§å¥½
3. Tushare - åŒèŠ±é¡ºæ¿å—æ—¥è¡Œæƒ… (ths_daily) - éœ€è¦ç§¯åˆ†ï¼Œç¨³å®šå¯é 

é‡‡é›†é€»è¾‘:
1. æŒ‰ä¼˜å…ˆçº§å°è¯•å„æ•°æ®æº
2. ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ•°æ®æºå®Œæˆé‡‡é›†
3. æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥æ—¶è®°å½•é”™è¯¯
4. é‡‡é›†åè®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„æ¶¨åœè‚¡æ•°é‡
"""

import akshare as ak
import pandas as pd
import os
import time
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Tuple, Set
from loguru import logger
from enum import Enum

from app.utils.supabase_client import get_supabase


class DataSource(Enum):
    """æ•°æ®æºæšä¸¾"""
    AKSHARE_THS = "akshare_ths"      # AKShare åŒèŠ±é¡º
    AKSHARE_EM = "akshare_em"        # AKShare ä¸œæ–¹è´¢å¯Œ
    TUSHARE = "tushare"              # Tushare


class HotConceptsCollector:
    """çƒ­é—¨æ¦‚å¿µæ¿å—æ•°æ®é‡‡é›†å™¨ï¼ˆæ”¯æŒå¤šæ•°æ®æºé™çº§ï¼‰"""

    def __init__(self):
        self.supabase = get_supabase()
        self._tushare_pro = None

        # æ•°æ®æºä¼˜å…ˆçº§åˆ—è¡¨
        self.data_source_priority = [
            DataSource.AKSHARE_THS,
            DataSource.AKSHARE_EM,
            DataSource.TUSHARE,
        ]

    @property
    def tushare_pro(self):
        """æ‡’åŠ è½½ Tushare Pro API"""
        if self._tushare_pro is None:
            try:
                import tushare as ts
                token = os.getenv('TUSHARE_TOKEN')
                if token:
                    ts.set_token(token)
                    self._tushare_pro = ts.pro_api()
                    logger.debug("Tushare Pro API åˆå§‹åŒ–æˆåŠŸ")
                else:
                    logger.warning("TUSHARE_TOKEN æœªé…ç½®ï¼ŒTushare æ•°æ®æºä¸å¯ç”¨")
            except Exception as e:
                logger.warning(f"Tushare åˆå§‹åŒ–å¤±è´¥: {e}")
        return self._tushare_pro

    # ==================== æ•°æ®æº1: AKShare åŒèŠ±é¡º ====================

    def _collect_from_akshare_ths(self, trade_date: str, top_n: int) -> Tuple[List[Dict], bool]:
        """
        ä» AKShare åŒèŠ±é¡ºæ¥å£é‡‡é›†æ•°æ®

        Returns:
            (æ•°æ®åˆ—è¡¨, æ˜¯å¦æˆåŠŸ)
        """
        logger.info("ğŸ”„ å°è¯•æ•°æ®æº: AKShare åŒèŠ±é¡º...")

        try:
            # è·å–æ¦‚å¿µæ¿å—åˆ—è¡¨
            concepts_df = ak.stock_board_concept_name_ths()

            if concepts_df is None or concepts_df.empty:
                logger.warning("AKShare åŒèŠ±é¡º: æ¦‚å¿µæ¿å—åˆ—è¡¨ä¸ºç©º")
                return [], False

            logger.info(f"   è·å–åˆ° {len(concepts_df)} ä¸ªæ¦‚å¿µæ¿å—")

            # å‡†å¤‡æ—¥æœŸå‚æ•°
            date_obj = datetime.strptime(trade_date, "%Y-%m-%d")
            end_date_str = date_obj.strftime("%Y%m%d")
            start_date_str = (date_obj - timedelta(days=15)).strftime("%Y%m%d")

            hot_concepts = []
            total = len(concepts_df)

            for idx, row in concepts_df.iterrows():
                try:
                    concept_name = str(row.get('name', ''))
                    if not concept_name:
                        continue

                    # è·å–æ¦‚å¿µæŒ‡æ•°æ•°æ®
                    index_df = ak.stock_board_concept_index_ths(
                        symbol=concept_name,
                        start_date=start_date_str,
                        end_date=end_date_str
                    )

                    if index_df is None or index_df.empty:
                        continue

                    # å–æœ€å5ä¸ªäº¤æ˜“æ—¥
                    last_5_days = index_df.tail(5) if len(index_df) >= 5 else index_df
                    if len(last_5_days) < 2:
                        continue

                    # è·å–æœ€æ–°æ•°æ®
                    latest = last_5_days.iloc[-1]
                    actual_trade_date = pd.to_datetime(latest['æ—¥æœŸ']).strftime("%Y-%m-%d")

                    # è®¡ç®—å½“æ—¥æ¶¨å¹…ï¼ˆä»Šæ—¥æ”¶ç›˜ä»· vs æ˜¨æ—¥æ”¶ç›˜ä»·ï¼‰
                    day_close = latest['æ”¶ç›˜ä»·']
                    prev_close = last_5_days.iloc[-2]['æ”¶ç›˜ä»·'] if len(last_5_days) >= 2 else day_close
                    day_change_pct = ((day_close - prev_close) / prev_close) * 100 if prev_close > 0 else 0

                    # è®¡ç®—è¿‘5æ—¥ç´¯è®¡æ¶¨å¹…
                    first_close = last_5_days.iloc[0]['æ”¶ç›˜ä»·']
                    total_change_pct = ((day_close - first_close) / first_close) * 100

                    hot_concepts.append({
                        "trade_date": actual_trade_date,
                        "concept_name": concept_name,
                        "day_change_pct": round(day_change_pct, 2),
                        "change_pct": round(total_change_pct, 2),
                        "consecutive_days": 1,
                        "concept_strength": round(total_change_pct, 4),
                        "rank": 0,
                        "is_new_concept": len(last_5_days) < 5,
                        "first_seen_date": actual_trade_date if len(last_5_days) < 5 else (
                            datetime.strptime(actual_trade_date, "%Y-%m-%d") - timedelta(days=30)
                        ).strftime("%Y-%m-%d"),
                        "data_source": DataSource.AKSHARE_THS.value,
                    })

                    if (idx + 1) % 50 == 0:
                        logger.info(f"   å·²å¤„ç† {idx + 1}/{total} ä¸ªæ¦‚å¿µ")

                except Exception as e:
                    logger.debug(f"å¤„ç†æ¦‚å¿µå¤±è´¥: {concept_name}, {e}")
                    continue

            if not hot_concepts:
                return [], False

            # æ’åºå¹¶å– top_n
            hot_concepts.sort(key=lambda x: x['change_pct'], reverse=True)
            hot_concepts = hot_concepts[:top_n]

            for rank, c in enumerate(hot_concepts, 1):
                c['rank'] = rank

            logger.info(f"âœ… AKShare åŒèŠ±é¡º: æˆåŠŸé‡‡é›† {len(hot_concepts)} ä¸ªæ¦‚å¿µ")
            return hot_concepts, True

        except Exception as e:
            logger.warning(f"âŒ AKShare åŒèŠ±é¡ºå¤±è´¥: {e}")
            return [], False

    # ==================== æ•°æ®æº2: AKShare ä¸œæ–¹è´¢å¯Œ ====================

    def _collect_from_akshare_em(self, trade_date: str, top_n: int) -> Tuple[List[Dict], bool]:
        """
        ä» AKShare ä¸œæ–¹è´¢å¯Œæ¥å£é‡‡é›†æ•°æ®

        Returns:
            (æ•°æ®åˆ—è¡¨, æ˜¯å¦æˆåŠŸ)
        """
        logger.info("ğŸ”„ å°è¯•æ•°æ®æº: AKShare ä¸œæ–¹è´¢å¯Œ...")

        try:
            # è·å–æ¦‚å¿µæ¿å—åˆ—è¡¨ï¼ˆåŒ…å«å®æ—¶æ¶¨è·Œå¹…ï¼‰
            concepts_df = ak.stock_board_concept_name_em()

            if concepts_df is None or concepts_df.empty:
                logger.warning("AKShare ä¸œæ–¹è´¢å¯Œ: æ¦‚å¿µæ¿å—åˆ—è¡¨ä¸ºç©º")
                return [], False

            logger.info(f"   è·å–åˆ° {len(concepts_df)} ä¸ªæ¦‚å¿µæ¿å—")

            # ä¸œæ–¹è´¢å¯Œæ¥å£ç›´æ¥è¿”å›å½“æ—¥æ¶¨è·Œå¹…
            # åˆ—å: ['æ’å', 'æ¿å—åç§°', 'æ¿å—ä»£ç ', 'æœ€æ–°ä»·', 'æ¶¨è·Œé¢', 'æ¶¨è·Œå¹…', ...]
            hot_concepts = []

            for idx, row in concepts_df.iterrows():
                try:
                    concept_name = str(row.get('æ¿å—åç§°', ''))
                    change_pct = float(row.get('æ¶¨è·Œå¹…', 0))

                    if not concept_name:
                        continue

                    hot_concepts.append({
                        "trade_date": trade_date,
                        "concept_name": concept_name,
                        "day_change_pct": round(change_pct, 2),
                        "change_pct": round(change_pct, 2),  # ä¸œæ–¹è´¢å¯Œåªæœ‰å½“æ—¥æ•°æ®
                        "consecutive_days": 1,
                        "concept_strength": round(change_pct, 4),
                        "rank": 0,
                        "is_new_concept": False,
                        "first_seen_date": (
                            datetime.strptime(trade_date, "%Y-%m-%d") - timedelta(days=30)
                        ).strftime("%Y-%m-%d"),
                        "data_source": DataSource.AKSHARE_EM.value,
                    })

                except Exception as e:
                    logger.debug(f"å¤„ç†æ¦‚å¿µå¤±è´¥: {e}")
                    continue

            if not hot_concepts:
                return [], False

            # æ’åºå¹¶å– top_n
            hot_concepts.sort(key=lambda x: x['change_pct'], reverse=True)
            hot_concepts = hot_concepts[:top_n]

            for rank, c in enumerate(hot_concepts, 1):
                c['rank'] = rank

            logger.info(f"âœ… AKShare ä¸œæ–¹è´¢å¯Œ: æˆåŠŸé‡‡é›† {len(hot_concepts)} ä¸ªæ¦‚å¿µ")
            return hot_concepts, True

        except Exception as e:
            logger.warning(f"âŒ AKShare ä¸œæ–¹è´¢å¯Œå¤±è´¥: {e}")
            return [], False

    # ==================== æ•°æ®æº3: Tushare ====================

    def _collect_from_tushare(self, trade_date: str, top_n: int) -> Tuple[List[Dict], bool]:
        """
        ä» Tushare åŒèŠ±é¡ºæ¿å—æ—¥è¡Œæƒ…æ¥å£é‡‡é›†æ•°æ®

        æ’åºé€»è¾‘: æŒ‰è¿‘5æ—¥ç´¯è®¡æ¶¨å¹…é™åºæ’åºï¼Œå–å‰ top_n å

        Returns:
            (æ•°æ®åˆ—è¡¨, æ˜¯å¦æˆåŠŸ)
        """
        logger.info("ğŸ”„ å°è¯•æ•°æ®æº: Tushare...")

        if self.tushare_pro is None:
            logger.warning("âŒ Tushare: API æœªåˆå§‹åŒ–")
            return [], False

        try:
            # è·å–åŒèŠ±é¡ºæ¦‚å¿µæ¿å—åˆ—è¡¨
            index_df = self.tushare_pro.ths_index()
            concept_list = index_df[index_df['type'] == 'N']

            if concept_list.empty:
                logger.warning("Tushare: æ¦‚å¿µæ¿å—åˆ—è¡¨ä¸ºç©º")
                return [], False

            logger.info(f"   è·å–åˆ° {len(concept_list)} ä¸ªæ¦‚å¿µæ¿å—")

            # è·å–æŒ‡å®šæ—¥æœŸçš„æ¿å—æ—¥è¡Œæƒ…ï¼ˆå½“æ—¥æ•°æ®ï¼‰
            date_str = trade_date.replace("-", "")
            daily_df = self.tushare_pro.ths_daily(trade_date=date_str)

            if daily_df is None or daily_df.empty:
                logger.warning(f"Tushare: {trade_date} æ— æ¿å—æ—¥è¡Œæƒ…æ•°æ®")
                return [], False

            logger.info(f"   è·å–åˆ° {len(daily_df)} æ¡å½“æ—¥è¡Œæƒ…")

            # åˆå¹¶æ•°æ®ï¼Œåªä¿ç•™æ¦‚å¿µæ¿å—
            concept_codes = set(concept_list['ts_code'].tolist())
            concept_daily = daily_df[daily_df['ts_code'].isin(concept_codes)].copy()

            if concept_daily.empty:
                logger.warning("Tushare: æ— æ¦‚å¿µæ¿å—æ—¥è¡Œæƒ…æ•°æ®")
                return [], False

            # åˆå¹¶æ¦‚å¿µåç§°
            concept_daily = concept_daily.merge(
                concept_list[['ts_code', 'name']],
                on='ts_code',
                how='left'
            )

            # è®¡ç®—è¿‘5æ—¥ç´¯è®¡æ¶¨å¹…
            logger.info("   æ­£åœ¨è®¡ç®—è¿‘5æ—¥ç´¯è®¡æ¶¨å¹…...")
            five_day_change = self._calculate_5day_change_tushare(concept_daily, trade_date)

            # åˆå¹¶è¿‘5æ—¥æ¶¨å¹…æ•°æ®
            concept_daily = concept_daily.merge(
                five_day_change,
                on='ts_code',
                how='left'
            )

            # å¡«å……ç¼ºå¤±çš„è¿‘5æ—¥æ¶¨å¹…ï¼ˆç”¨å½“æ—¥æ¶¨å¹…ï¼‰
            concept_daily['change_5d'] = concept_daily['change_5d'].fillna(concept_daily['pct_change'])

            # æŒ‰è¿‘5æ—¥æ¶¨å¹…é™åºæ’åº
            concept_daily = concept_daily.sort_values('change_5d', ascending=False)

            hot_concepts = []
            for rank, (_, row) in enumerate(concept_daily.head(top_n).iterrows(), 1):
                hot_concepts.append({
                    "trade_date": trade_date,
                    "concept_name": row['name'],
                    "day_change_pct": round(float(row['pct_change']), 2),
                    "change_pct": round(float(row['change_5d']), 2),  # è¿‘5æ—¥æ¶¨å¹…
                    "consecutive_days": 1,
                    "concept_strength": round(float(row['change_5d']), 4),
                    "rank": rank,
                    "is_new_concept": False,
                    "first_seen_date": (
                        datetime.strptime(trade_date, "%Y-%m-%d") - timedelta(days=30)
                    ).strftime("%Y-%m-%d"),
                    "data_source": DataSource.TUSHARE.value,
                })

            logger.info(f"âœ… Tushare: æˆåŠŸé‡‡é›† {len(hot_concepts)} ä¸ªæ¦‚å¿µï¼ˆæŒ‰è¿‘5æ—¥æ¶¨å¹…æ’åºï¼‰")
            return hot_concepts, True

        except Exception as e:
            logger.warning(f"âŒ Tushare å¤±è´¥: {e}")
            return [], False

    def _calculate_5day_change_tushare(self, concept_daily: pd.DataFrame, trade_date: str) -> pd.DataFrame:
        """
        è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„è¿‘5æ—¥ç´¯è®¡æ¶¨å¹…

        Args:
            concept_daily: å½“æ—¥æ¦‚å¿µè¡Œæƒ…æ•°æ®
            trade_date: äº¤æ˜“æ—¥æœŸ

        Returns:
            åŒ…å« ts_code å’Œ change_5d çš„ DataFrame
        """
        try:
            # è·å–è¿‘10ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®ï¼ˆç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®ï¼‰
            date_obj = datetime.strptime(trade_date, "%Y-%m-%d")
            start_date = (date_obj - timedelta(days=15)).strftime("%Y%m%d")
            end_date = trade_date.replace("-", "")

            # è·å–å†å²è¡Œæƒ…
            history_df = self.tushare_pro.ths_daily(
                start_date=start_date,
                end_date=end_date
            )

            if history_df is None or history_df.empty:
                logger.warning("   æ— æ³•è·å–å†å²è¡Œæƒ…ï¼Œä½¿ç”¨å½“æ—¥æ¶¨å¹…")
                return pd.DataFrame(columns=['ts_code', 'change_5d'])

            # æŒ‰æ¦‚å¿µä»£ç å’Œæ—¥æœŸæ’åº
            history_df = history_df.sort_values(['ts_code', 'trade_date'])

            # è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„è¿‘5æ—¥ç´¯è®¡æ¶¨å¹…
            results = []
            for ts_code in concept_daily['ts_code'].unique():
                code_data = history_df[history_df['ts_code'] == ts_code].tail(5)

                if len(code_data) >= 2:
                    # ç”¨æ”¶ç›˜ä»·è®¡ç®—ç´¯è®¡æ¶¨å¹…: (æœ€æ–°æ”¶ç›˜ä»· / 5æ—¥å‰æ”¶ç›˜ä»· - 1) * 100
                    first_close = code_data.iloc[0]['close']
                    last_close = code_data.iloc[-1]['close']

                    if first_close > 0:
                        change_5d = ((last_close / first_close) - 1) * 100
                    else:
                        change_5d = code_data['pct_change'].sum()  # é€€åŒ–ä¸ºæ¶¨å¹…ç´¯åŠ 
                else:
                    # æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨å½“æ—¥æ¶¨å¹…
                    change_5d = code_data['pct_change'].iloc[-1] if len(code_data) > 0 else 0

                results.append({
                    'ts_code': ts_code,
                    'change_5d': round(change_5d, 2)
                })

            logger.info(f"   æˆåŠŸè®¡ç®— {len(results)} ä¸ªæ¦‚å¿µçš„è¿‘5æ—¥æ¶¨å¹…")
            return pd.DataFrame(results)

        except Exception as e:
            logger.warning(f"   è®¡ç®—è¿‘5æ—¥æ¶¨å¹…å¤±è´¥: {e}")
            return pd.DataFrame(columns=['ts_code', 'change_5d'])

    # ==================== ä¸»é‡‡é›†æ–¹æ³• ====================

    def collect_hot_concepts(self, trade_date: Optional[str] = None, top_n: int = 50) -> List[Dict]:
        """
        é‡‡é›†çƒ­é—¨æ¦‚å¿µæ¿å—æ•°æ®ï¼ˆè‡ªåŠ¨é™çº§å¤šæ•°æ®æºï¼‰

        æŒ‰ä¼˜å…ˆçº§å°è¯•å„æ•°æ®æºï¼š
        1. AKShare åŒèŠ±é¡º - æ•°æ®æœ€ä¸°å¯Œï¼Œæœ‰5æ—¥ç´¯è®¡æ¶¨å¹…
        2. AKShare ä¸œæ–¹è´¢å¯Œ - å®æ—¶æ€§å¥½ï¼Œåªæœ‰å½“æ—¥æ¶¨å¹…
        3. Tushare - æœ€ç¨³å®šï¼Œéœ€è¦ç§¯åˆ†

        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ YYYY-MM-DDï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»Šå¤©ï¼‰
            top_n: è¿”å›å‰Nä¸ªçƒ­é—¨æ¦‚å¿µ

        Returns:
            çƒ­é—¨æ¦‚å¿µæ•°æ®åˆ—è¡¨
        """
        if not trade_date:
            trade_date = datetime.now().strftime("%Y-%m-%d")

        logger.info(f"=" * 50)
        logger.info(f"å¼€å§‹é‡‡é›† {trade_date} çƒ­é—¨æ¦‚å¿µæ¿å—æ•°æ®...")
        logger.info(f"æ•°æ®æºä¼˜å…ˆçº§: {' -> '.join(ds.value for ds in self.data_source_priority)}")
        logger.info(f"=" * 50)

        # æŒ‰ä¼˜å…ˆçº§å°è¯•å„æ•°æ®æº
        collectors = {
            DataSource.AKSHARE_THS: self._collect_from_akshare_ths,
            DataSource.AKSHARE_EM: self._collect_from_akshare_em,
            DataSource.TUSHARE: self._collect_from_tushare,
        }

        for data_source in self.data_source_priority:
            collector_func = collectors.get(data_source)
            if collector_func:
                concepts, success = collector_func(trade_date, top_n)
                if success and concepts:
                    # æ›´æ–°è¿ç»­ä¸Šæ¦œå¤©æ•°ï¼ˆåŸºäºæ•°æ®åº“å†å²ï¼‰
                    for concept in concepts:
                        concept['consecutive_days'] = self.get_consecutive_days(
                            concept['concept_name'],
                            concept['trade_date']
                        )

                    # è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„æ¶¨åœè‚¡æ•°é‡
                    concepts = self._calculate_limit_up_count(concepts, trade_date)

                    # è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„é¾™å¤´è‚¡
                    concepts = self._calculate_leader_stock(concepts, trade_date)

                    self._log_top_concepts(concepts, data_source)
                    return concepts

        logger.error("âŒ æ‰€æœ‰æ•°æ®æºéƒ½é‡‡é›†å¤±è´¥ï¼")
        return []

    def _log_top_concepts(self, concepts: List[Dict], data_source: DataSource):
        """æ‰“å°é‡‡é›†ç»“æœæ‘˜è¦"""
        logger.info(f"\n{'=' * 50}")
        logger.info(f"ğŸ“Š é‡‡é›†å®Œæˆ - æ•°æ®æº: {data_source.value}")
        logger.info(f"   äº¤æ˜“æ—¥æœŸ: {concepts[0]['trade_date'] if concepts else 'N/A'}")
        logger.info(f"   æ¦‚å¿µæ•°é‡: {len(concepts)}")
        logger.info(f"\n   æ¶¨å¹…å‰5çš„æ¦‚å¿µ:")
        for c in concepts[:5]:
            logger.info(f"   [{c['rank']}] {c['concept_name']}: {c['change_pct']}%")
        logger.info(f"{'=' * 50}\n")

    # ==================== æ¶¨åœè‚¡æ•°é‡è®¡ç®— ====================

    def _get_limit_up_stocks(self, trade_date: str) -> Set[str]:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„æ¶¨åœè‚¡ä»£ç é›†åˆï¼ˆä¼˜å…ˆä»AKShareè·å–å®æ—¶æ•°æ®ï¼‰

        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ YYYY-MM-DD

        Returns:
            æ¶¨åœè‚¡ä»£ç é›†åˆï¼ˆå¸¦äº¤æ˜“æ‰€åç¼€ï¼Œå¦‚ 300081.SZï¼‰
        """
        limit_up_stocks = set()

        # æ–¹æ³•1: ä» AKShare è·å–å®æ—¶æ¶¨åœæ•°æ®
        try:
            logger.debug("   å°è¯•ä» AKShare è·å–æ¶¨åœè‚¡æ•°æ®...")
            # è·å–ä»Šæ—¥æ¶¨åœè‚¡
            limit_up_df = ak.stock_zt_pool_em(date=trade_date.replace("-", ""))

            if limit_up_df is not None and not limit_up_df.empty:
                for _, row in limit_up_df.iterrows():
                    code = str(row.get('ä»£ç ', ''))
                    if code:
                        # è½¬æ¢ä¸ºå¸¦äº¤æ˜“æ‰€åç¼€çš„æ ¼å¼
                        if code.startswith('6'):
                            limit_up_stocks.add(f"{code}.SH")
                        else:
                            limit_up_stocks.add(f"{code}.SZ")

                logger.debug(f"   AKShare è·å–åˆ° {len(limit_up_stocks)} åªæ¶¨åœè‚¡")
                return limit_up_stocks

        except Exception as e:
            logger.debug(f"   AKShare è·å–æ¶¨åœè‚¡å¤±è´¥: {e}")

        # æ–¹æ³•2: ä»æ•°æ®åº“è·å–ï¼ˆå¤‡ç”¨ï¼‰
        try:
            result = self.supabase.table('limit_stocks_detail')\
                .select('stock_code')\
                .eq('trade_date', trade_date)\
                .eq('limit_type', 'limit_up')\
                .execute()

            for row in result.data:
                code = row['stock_code']
                # è½¬æ¢ä¸ºå¸¦äº¤æ˜“æ‰€åç¼€çš„æ ¼å¼
                if code.startswith('6'):
                    limit_up_stocks.add(f"{code}.SH")
                else:
                    limit_up_stocks.add(f"{code}.SZ")

            if limit_up_stocks:
                logger.debug(f"   æ•°æ®åº“è·å–åˆ° {len(limit_up_stocks)} åªæ¶¨åœè‚¡")

            return limit_up_stocks
        except Exception as e:
            logger.warning(f"è·å–æ¶¨åœè‚¡åˆ—è¡¨å¤±è´¥: {e}")
            return set()

    def _get_concept_code_mapping(self) -> Dict[str, str]:
        """
        è·å–æ¦‚å¿µåç§°åˆ°æ¦‚å¿µä»£ç çš„æ˜ å°„

        Returns:
            {æ¦‚å¿µåç§°: æ¦‚å¿µä»£ç } å­—å…¸
        """
        if self.tushare_pro is None:
            return {}

        try:
            index_df = self.tushare_pro.ths_index()
            concept_list = index_df[index_df['type'] == 'N'][['ts_code', 'name']]
            return dict(zip(concept_list['name'], concept_list['ts_code']))
        except Exception as e:
            logger.warning(f"è·å–æ¦‚å¿µä»£ç æ˜ å°„å¤±è´¥: {e}")
            return {}

    def _calculate_limit_up_count(self, concepts: List[Dict], trade_date: str) -> List[Dict]:
        """
        è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„æ¶¨åœè‚¡æ•°é‡

        Args:
            concepts: æ¦‚å¿µæ•°æ®åˆ—è¡¨
            trade_date: äº¤æ˜“æ—¥æœŸ

        Returns:
            æ·»åŠ äº† limit_up_count å­—æ®µçš„æ¦‚å¿µæ•°æ®åˆ—è¡¨
        """
        logger.info("ğŸ“Š å¼€å§‹è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„æ¶¨åœè‚¡æ•°é‡...")

        # è·å–ä»Šæ—¥æ¶¨åœè‚¡
        limit_up_stocks = self._get_limit_up_stocks(trade_date)
        if not limit_up_stocks:
            logger.warning("   æœªè·å–åˆ°æ¶¨åœè‚¡æ•°æ®ï¼Œè·³è¿‡æ¶¨åœæ•°è®¡ç®—")
            for concept in concepts:
                concept['limit_up_count'] = None
            return concepts

        logger.info(f"   ä»Šæ—¥æ¶¨åœè‚¡: {len(limit_up_stocks)} åª")

        # è·å–æ¦‚å¿µä»£ç æ˜ å°„
        concept_code_mapping = self._get_concept_code_mapping()
        if not concept_code_mapping:
            logger.warning("   æœªè·å–åˆ°æ¦‚å¿µä»£ç æ˜ å°„ï¼Œè·³è¿‡æ¶¨åœæ•°è®¡ç®—")
            for concept in concepts:
                concept['limit_up_count'] = None
            return concepts

        # ç¼“å­˜å·²æŸ¥è¯¢çš„æ¦‚å¿µæˆåˆ†è‚¡
        concept_members_cache: Dict[str, Set[str]] = {}

        for concept in concepts:
            concept_name = concept['concept_name']

            # æŸ¥æ‰¾æ¦‚å¿µä»£ç ï¼ˆå¤„ç†æ‹¬å·ç­‰ç‰¹æ®Šå­—ç¬¦ï¼‰
            ts_code = None

            # ç²¾ç¡®åŒ¹é…
            if concept_name in concept_code_mapping:
                ts_code = concept_code_mapping[concept_name]
            else:
                # æ¨¡ç³ŠåŒ¹é…ï¼ˆå»æ‰æ‹¬å·ï¼‰
                search_name = concept_name.replace('(', '').replace(')', '').replace('ï¼ˆ', '').replace('ï¼‰', '')
                for name, code in concept_code_mapping.items():
                    clean_name = name.replace('(', '').replace(')', '').replace('ï¼ˆ', '').replace('ï¼‰', '')
                    if clean_name == search_name or search_name in clean_name or clean_name in search_name:
                        ts_code = code
                        break

            if not ts_code:
                concept['limit_up_count'] = None
                continue

            # æ£€æŸ¥ç¼“å­˜
            if ts_code in concept_members_cache:
                member_codes = concept_members_cache[ts_code]
            else:
                member_codes = set()
                # ä» Tushare è·å–æˆåˆ†è‚¡ï¼ˆä¸»è¦æ–¹æ³•ï¼‰
                if self.tushare_pro:
                    try:
                        time.sleep(0.3)  # é¿å…é¢‘ç‡é™åˆ¶
                        members = self.tushare_pro.ths_member(ts_code=ts_code)
                        if members is not None and not members.empty:
                            member_codes = set(members['con_code'].tolist())
                            logger.debug(f"   Tushareè·å– {concept_name} æˆåˆ†è‚¡: {len(member_codes)} åª")
                    except Exception as e:
                        logger.debug(f"   Tushareè·å– {concept_name} æˆåˆ†è‚¡å¤±è´¥: {e}")

                if member_codes:
                    concept_members_cache[ts_code] = member_codes
                else:
                    concept['limit_up_count'] = None
                    continue

            # è®¡ç®—æ¶¨åœæ•°ï¼ˆæˆåˆ†è‚¡ä¸æ¶¨åœè‚¡çš„äº¤é›†ï¼‰
            limit_up_in_concept = limit_up_stocks & member_codes
            concept['limit_up_count'] = len(limit_up_in_concept)
            concept['total_count'] = len(member_codes)

        # ç»Ÿè®¡ç»“æœ
        calculated = [c for c in concepts if c.get('limit_up_count') is not None]
        logger.info(f"   æˆåŠŸè®¡ç®— {len(calculated)}/{len(concepts)} ä¸ªæ¦‚å¿µçš„æ¶¨åœè‚¡æ•°é‡")

        # æ˜¾ç¤ºæ¶¨åœæ•°æœ€å¤šçš„æ¦‚å¿µ
        top_limit_up = sorted(
            [c for c in concepts if c.get('limit_up_count')],
            key=lambda x: x['limit_up_count'],
            reverse=True
        )[:5]
        if top_limit_up:
            logger.info("   æ¶¨åœæ•° Top 5:")
            for c in top_limit_up:
                logger.info(f"      {c['concept_name']}: {c['limit_up_count']} åªæ¶¨åœ")

        return concepts

    def _get_limit_up_pool_data(self, trade_date: str) -> pd.DataFrame:
        """
        è·å–æ¶¨åœæ± å®Œæ•´æ•°æ®ï¼ˆåŒ…å«è¿æ¿æ•°ã€æ¶¨åœæ—¶é—´ç­‰ï¼‰

        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ YYYY-MM-DD

        Returns:
            æ¶¨åœæ±  DataFrame
        """
        try:
            limit_up_df = ak.stock_zt_pool_em(date=trade_date.replace("-", ""))
            if limit_up_df is not None and not limit_up_df.empty:
                return limit_up_df
        except Exception as e:
            logger.warning(f"è·å–æ¶¨åœæ± æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

    def _calculate_leader_stock(self, concepts: List[Dict], trade_date: str) -> List[Dict]:
        """
        è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„é¾™å¤´è‚¡

        é¾™å¤´è‚¡å®šä¹‰ï¼š
        1. ä¼˜å…ˆé€‰æ‹©è¿ç»­æ¶¨åœæ¬¡æ•°æœ€å¤šçš„
        2. è‹¥è¿æ¿æ•°ç›¸åŒï¼Œä¼˜å…ˆé€‰æ‹©åˆ›ä¸šæ¿(300)/ç§‘åˆ›æ¿(688)
        3. è‹¥æ¿å—ç›¸åŒï¼Œé€‰æ‹©å½“æ—¥æ¶¨å¹…æœ€å¤§çš„
        4. è‹¥æ¶¨å¹…ä¹Ÿç›¸åŒï¼Œé€‰æ‹©é¦–æ¬¡å°æ¿æ—¶é—´æœ€æ—©çš„

        Args:
            concepts: æ¦‚å¿µæ•°æ®åˆ—è¡¨
            trade_date: äº¤æ˜“æ—¥æœŸ

        Returns:
            æ·»åŠ äº†é¾™å¤´è‚¡ä¿¡æ¯çš„æ¦‚å¿µæ•°æ®åˆ—è¡¨
        """
        logger.info("ğŸ“Š å¼€å§‹è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„é¾™å¤´è‚¡...")

        # è·å–æ¶¨åœæ± æ•°æ®
        limit_up_df = self._get_limit_up_pool_data(trade_date)
        if limit_up_df.empty:
            logger.warning("   æœªè·å–åˆ°æ¶¨åœæ± æ•°æ®ï¼Œè·³è¿‡é¾™å¤´è‚¡è®¡ç®—")
            for concept in concepts:
                concept['leader_stock_code'] = None
                concept['leader_stock_name'] = None
                concept['leader_continuous_days'] = None
                concept['leader_change_pct'] = None
            return concepts

        logger.info(f"   æ¶¨åœæ± æ•°æ®: {len(limit_up_df)} åªè‚¡ç¥¨")

        # æ„å»ºæ¶¨åœè‚¡ä¿¡æ¯å­—å…¸ {code: {name, continuous_days, change_pct, first_time}}
        limit_up_info = {}
        for _, row in limit_up_df.iterrows():
            code = str(row.get('ä»£ç ', ''))
            if not code:
                continue
            # è½¬æ¢ä¸ºå¸¦äº¤æ˜“æ‰€åç¼€çš„æ ¼å¼
            if code.startswith('6'):
                full_code = f"{code}.SH"
            else:
                full_code = f"{code}.SZ"

            limit_up_info[full_code] = {
                'code': code,
                'name': str(row.get('åç§°', '')),
                'continuous_days': int(row.get('è¿æ¿æ•°', 1)),
                'change_pct': float(row.get('æ¶¨è·Œå¹…', 0)),
                'first_time': str(row.get('é¦–æ¬¡å°æ¿æ—¶é—´', '235959')),
            }

        # è·å–æ¦‚å¿µä»£ç æ˜ å°„
        concept_code_mapping = self._get_concept_code_mapping()

        # ç¼“å­˜å·²æŸ¥è¯¢çš„æ¦‚å¿µæˆåˆ†è‚¡
        concept_members_cache: Dict[str, Set[str]] = {}

        for concept in concepts:
            concept_name = concept['concept_name']

            # åˆå§‹åŒ–é¾™å¤´è‚¡å­—æ®µ
            concept['leader_stock_code'] = None
            concept['leader_stock_name'] = None
            concept['leader_continuous_days'] = None
            concept['leader_change_pct'] = None

            # æŸ¥æ‰¾æ¦‚å¿µä»£ç 
            ts_code = None
            if concept_name in concept_code_mapping:
                ts_code = concept_code_mapping[concept_name]
            else:
                search_name = concept_name.replace('(', '').replace(')', '').replace('ï¼ˆ', '').replace('ï¼‰', '')
                for name, code in concept_code_mapping.items():
                    clean_name = name.replace('(', '').replace(')', '').replace('ï¼ˆ', '').replace('ï¼‰', '')
                    if clean_name == search_name or search_name in clean_name or clean_name in search_name:
                        ts_code = code
                        break

            if not ts_code:
                continue

            # è·å–æ¦‚å¿µæˆåˆ†è‚¡
            if ts_code in concept_members_cache:
                member_codes = concept_members_cache[ts_code]
            else:
                member_codes = set()
                if self.tushare_pro:
                    try:
                        members = self.tushare_pro.ths_member(ts_code=ts_code)
                        if members is not None and not members.empty:
                            member_codes = set(members['con_code'].tolist())
                            concept_members_cache[ts_code] = member_codes
                    except Exception as e:
                        logger.debug(f"   è·å– {concept_name} æˆåˆ†è‚¡å¤±è´¥: {e}")

            if not member_codes:
                continue

            # æ‰¾å‡ºè¯¥æ¦‚å¿µä¸­çš„æ¶¨åœè‚¡
            concept_limit_up_stocks = []
            for code in member_codes:
                if code in limit_up_info:
                    stock_info = limit_up_info[code]
                    # åˆ¤æ–­æ˜¯å¦åˆ›ä¸šæ¿/ç§‘åˆ›æ¿
                    is_gem = stock_info['code'].startswith('300') or stock_info['code'].startswith('688')
                    concept_limit_up_stocks.append({
                        'code': stock_info['code'],
                        'name': stock_info['name'],
                        'continuous_days': stock_info['continuous_days'],
                        'change_pct': stock_info['change_pct'],
                        'first_time': stock_info['first_time'],
                        'is_gem': is_gem,
                    })

            if not concept_limit_up_stocks:
                continue

            # æ’åºæ‰¾é¾™å¤´ï¼š
            # 1. è¿æ¿æ•°é™åº
            # 2. åˆ›ä¸šæ¿/ç§‘åˆ›æ¿ä¼˜å…ˆ (is_gem=True ä¼˜å…ˆ)
            # 3. æ¶¨å¹…é™åº
            # 4. é¦–æ¬¡å°æ¿æ—¶é—´å‡åº
            concept_limit_up_stocks.sort(
                key=lambda x: (
                    -x['continuous_days'],  # è¿æ¿æ•°é™åº
                    not x['is_gem'],        # åˆ›ä¸šæ¿/ç§‘åˆ›æ¿ä¼˜å…ˆ (False < True, æ‰€ä»¥ not is_gem)
                    -x['change_pct'],       # æ¶¨å¹…é™åº
                    x['first_time'],        # é¦–æ¬¡å°æ¿æ—¶é—´å‡åº
                )
            )

            leader = concept_limit_up_stocks[0]
            concept['leader_stock_code'] = leader['code']
            concept['leader_stock_name'] = leader['name']
            concept['leader_continuous_days'] = leader['continuous_days']
            concept['leader_change_pct'] = round(leader['change_pct'], 2)

        # ç»Ÿè®¡ç»“æœ
        calculated = [c for c in concepts if c.get('leader_stock_code')]
        logger.info(f"   æˆåŠŸè®¡ç®— {len(calculated)}/{len(concepts)} ä¸ªæ¦‚å¿µçš„é¾™å¤´è‚¡")

        # æ˜¾ç¤ºéƒ¨åˆ†é¾™å¤´è‚¡
        if calculated:
            logger.info("   éƒ¨åˆ†æ¦‚å¿µé¾™å¤´è‚¡:")
            for c in calculated[:5]:
                logger.info(f"      {c['concept_name']}: {c['leader_stock_name']}({c['leader_stock_code']}) {c['leader_continuous_days']}è¿æ¿")

        return concepts

    def get_consecutive_days(self, concept_name: str, current_date: str, lookback_days: int = 10) -> int:
        """
        è®¡ç®—æ¦‚å¿µçš„è¿ç»­ä¸Šæ¦œæ¬¡æ•°

        Args:
            concept_name: æ¦‚å¿µåç§°
            current_date: å½“å‰æ—¥æœŸ YYYY-MM-DD
            lookback_days: å›æº¯å¤©æ•°ï¼Œé»˜è®¤10å¤©

        Returns:
            è¿ç»­ä¸Šæ¦œæ¬¡æ•°ï¼ˆåŒ…æ‹¬ä»Šå¤©ï¼‰
        """
        try:
            response = self.supabase.table("hot_concepts")\
                .select("trade_date")\
                .eq("concept_name", concept_name)\
                .lte("trade_date", current_date)\
                .order("trade_date", desc=True)\
                .limit(lookback_days)\
                .execute()

            if not response.data:
                return 1

            trade_dates = [r['trade_date'] for r in response.data]
            consecutive_count = 0
            current_check_date = datetime.strptime(current_date, "%Y-%m-%d")

            for trade_date_str in trade_dates:
                trade_date = datetime.strptime(trade_date_str, "%Y-%m-%d")
                days_diff = (current_check_date - trade_date).days

                if days_diff == 0:
                    consecutive_count = 1
                    current_check_date = trade_date
                elif days_diff <= 3 and consecutive_count > 0:
                    consecutive_count += 1
                    current_check_date = trade_date
                else:
                    break

            return consecutive_count if consecutive_count > 0 else 1

        except Exception as e:
            logger.debug(f"è®¡ç®—è¿ç»­ä¸Šæ¦œæ¬¡æ•°å¤±è´¥: {concept_name}, {e}")
            return 1

    def save_to_database(self, concepts: List[Dict]) -> int:
        """
        ä¿å­˜çƒ­é—¨æ¦‚å¿µæ•°æ®åˆ° Supabase

        Args:
            concepts: æ¦‚å¿µæ¿å—æ•°æ®åˆ—è¡¨

        Returns:
            æˆåŠŸä¿å­˜çš„è®°å½•æ•°
        """
        if not concepts:
            logger.warning("æ²¡æœ‰æ¦‚å¿µæ•°æ®éœ€è¦ä¿å­˜")
            return 0

        try:
            logger.info(f"å‡†å¤‡ä¿å­˜ {len(concepts)} ä¸ªçƒ­é—¨æ¦‚å¿µæ•°æ®...")

            # ç§»é™¤ data_source å­—æ®µï¼ˆæ•°æ®åº“å¯èƒ½æ²¡æœ‰è¿™ä¸ªåˆ—ï¼‰
            records = []
            for c in concepts:
                record = {k: v for k, v in c.items() if k != 'data_source'}
                records.append(record)

            response = self.supabase.table("hot_concepts").upsert(
                records, on_conflict="trade_date,concept_name"
            ).execute()

            logger.info(f"âœ… æˆåŠŸä¿å­˜ {len(records)} ä¸ªçƒ­é—¨æ¦‚å¿µæ•°æ®")
            return len(records)

        except Exception as e:
            logger.error(f"ä¿å­˜çƒ­é—¨æ¦‚å¿µæ•°æ®å¤±è´¥: {e}")
            return 0

    def collect_and_save(self, trade_date: Optional[str] = None, top_n: int = 50) -> int:
        """
        é‡‡é›†å¹¶ä¿å­˜çƒ­é—¨æ¦‚å¿µæ•°æ®

        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ YYYY-MM-DD
            top_n: ä¿å­˜å‰Nä¸ªçƒ­é—¨æ¦‚å¿µ

        Returns:
            æˆåŠŸä¿å­˜çš„è®°å½•æ•°
        """
        hot_concepts = self.collect_hot_concepts(trade_date, top_n)
        return self.save_to_database(hot_concepts)


# ä¾¿æ·å‡½æ•°
def collect_hot_concepts(trade_date: Optional[str] = None, top_n: int = 50) -> int:
    """é‡‡é›†çƒ­é—¨æ¦‚å¿µæ¿å—æ•°æ®"""
    collector = HotConceptsCollector()
    return collector.collect_and_save(trade_date, top_n)
