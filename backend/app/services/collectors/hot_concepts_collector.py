"""
çƒ­é—¨æ¦‚å¿µæ¿å—æ•°æ®é‡‡é›†æœåŠ¡
æ”¯æŒå¤šæ•°æ®æºè‡ªåŠ¨é™çº§æœºåˆ¶

æ•°æ®æºä¼˜å…ˆçº§ï¼ˆTushareä¼˜å…ˆï¼Œä¿è¯æ¦‚å¿µåç§°ç»Ÿä¸€ï¼‰:
1. Tushare - åŒèŠ±é¡ºæ¿å—æ—¥è¡Œæƒ… (ths_daily + ths_index) - éœ€è¦ç§¯åˆ†ï¼Œæ•°æ®æœ€å¯é ï¼Œæ¦‚å¿µåç§°ç»Ÿä¸€ï¼Œå¯è®¡ç®—5æ—¥æ¶¨å¹…
2. AKShare - åŒèŠ±é¡ºæ¦‚å¿µæ¿å— (stock_board_concept_name_ths) - å…è´¹ï¼Œæ•°æ®ä¸°å¯Œï¼Œå¤‡ç”¨æ–¹æ¡ˆ
3. AKShare - ä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å— (stock_board_concept_name_em) - å…è´¹ï¼Œå®æ—¶æ€§å¥½ï¼Œæœ€ç»ˆå¤‡ç”¨

é‡‡é›†é€»è¾‘:
1. æŒ‰ä¼˜å…ˆçº§å°è¯•å„æ•°æ®æº
2. ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ•°æ®æºå®Œæˆé‡‡é›†
3. æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥æ—¶è®°å½•é”™è¯¯
4. é‡‡é›†åè®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„æ¶¨åœè‚¡æ•°é‡å’Œé¾™å¤´è‚¡
5. Tushareæ•°æ®æºè¿”å›ts_codeï¼Œé¿å…åç§°åŒ¹é…é—®é¢˜ï¼Œä½¿ç”¨5æ—¥æ¶¨å¹…æ’åº
"""

import akshare as ak
import pandas as pd
import os
import time
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Tuple, Set
from loguru import logger
from enum import Enum

from app.utils.supabase_client import get_supabase


class DataSource(Enum):
    """æ•°æ®æºæšä¸¾"""
    AKSHARE_THS = "akshare_ths"      # AKShare åŒèŠ±é¡º
    AKSHARE_EM = "akshare_em"        # AKShare ä¸œæ–¹è´¢å¯Œ
    TUSHARE = "tushare"              # Tushare


class HotConceptsCollector:
    """çƒ­é—¨æ¦‚å¿µæ¿å—æ•°æ®é‡‡é›†å™¨ï¼ˆæ”¯æŒå¤šæ•°æ®æºé™çº§ï¼‰"""

    def __init__(self):
        self.supabase = get_supabase()
        self._tushare_pro = None

        # æ•°æ®æºä¼˜å…ˆçº§åˆ—è¡¨ï¼ˆTushareä¼˜å…ˆï¼Œä¿è¯æ¦‚å¿µåç§°ç»Ÿä¸€ï¼‰
        self.data_source_priority = [
            DataSource.TUSHARE,        # ä¼˜å…ˆï¼šæ¦‚å¿µåç§°ç»Ÿä¸€ï¼Œæœ‰5æ—¥å†å²æ•°æ®
            DataSource.AKSHARE_THS,    # å¤‡ç”¨ï¼šæœ‰å®Œæ•´çš„5æ—¥å†å²æ•°æ®
            DataSource.AKSHARE_EM,     # å¤‡ç”¨ï¼šä¸œæ–¹è´¢å¯Œåªæœ‰å½“æ—¥æ•°æ®
        ]

    @property
    def tushare_pro(self):
        """æ‡’åŠ è½½ Tushare Pro APIï¼ˆæ”¯æŒé«˜çº§è´¦å·é…ç½®ï¼‰"""
        if self._tushare_pro is None:
            try:
                import tushare as ts
                token = os.getenv('TUSHARE_TOKEN')
                if token:
                    ts.set_token(token)
                    self._tushare_pro = ts.pro_api()

                    # é…ç½®é«˜çº§è´¦å·çš„è‡ªå®šä¹‰HTTP URLï¼ˆå¦‚æœæä¾›ï¼‰
                    http_url = os.getenv('TUSHARE_HTTP_URL')
                    if http_url:
                        self._tushare_pro._DataApi__token = token
                        self._tushare_pro._DataApi__http_url = http_url
                        logger.info(f"âœ… Tushare Pro API åˆå§‹åŒ–æˆåŠŸï¼ˆé«˜çº§è´¦å·ï¼‰: {http_url}")
                    else:
                        logger.debug("Tushare Pro API åˆå§‹åŒ–æˆåŠŸï¼ˆæ ‡å‡†è´¦å·ï¼‰")
                else:
                    logger.warning("TUSHARE_TOKEN æœªé…ç½®ï¼ŒTushare æ•°æ®æºä¸å¯ç”¨")
            except Exception as e:
                logger.warning(f"Tushare åˆå§‹åŒ–å¤±è´¥: {e}")
        return self._tushare_pro

    # ==================== æ•°æ®æº1: AKShare åŒèŠ±é¡º ====================

    def _collect_from_akshare_ths(self, trade_date: str, top_n: int) -> Tuple[List[Dict], bool]:
        """
        ä» AKShare åŒèŠ±é¡ºæ¥å£é‡‡é›†æ•°æ®

        Returns:
            (æ•°æ®åˆ—è¡¨, æ˜¯å¦æˆåŠŸ)
        """
        logger.info("ğŸ”„ å°è¯•æ•°æ®æº: AKShare åŒèŠ±é¡º...")

        try:
            # è·å–æ¦‚å¿µæ¿å—åˆ—è¡¨
            concepts_df = ak.stock_board_concept_name_ths()

            if concepts_df is None or concepts_df.empty:
                logger.warning("AKShare åŒèŠ±é¡º: æ¦‚å¿µæ¿å—åˆ—è¡¨ä¸ºç©º")
                return [], False

            logger.info(f"   è·å–åˆ° {len(concepts_df)} ä¸ªæ¦‚å¿µæ¿å—")

            # å‡†å¤‡æ—¥æœŸå‚æ•°
            date_obj = datetime.strptime(trade_date, "%Y-%m-%d")
            end_date_str = date_obj.strftime("%Y%m%d")
            start_date_str = (date_obj - timedelta(days=15)).strftime("%Y%m%d")

            hot_concepts = []
            total = len(concepts_df)

            for idx, row in concepts_df.iterrows():
                try:
                    concept_name = str(row.get('name', ''))
                    if not concept_name:
                        continue

                    # è·å–æ¦‚å¿µæŒ‡æ•°æ•°æ®
                    index_df = ak.stock_board_concept_index_ths(
                        symbol=concept_name,
                        start_date=start_date_str,
                        end_date=end_date_str
                    )

                    if index_df is None or index_df.empty:
                        continue

                    # å–æœ€å5ä¸ªäº¤æ˜“æ—¥
                    last_5_days = index_df.tail(5) if len(index_df) >= 5 else index_df
                    if len(last_5_days) < 2:
                        continue

                    # è·å–æœ€æ–°æ•°æ®
                    latest = last_5_days.iloc[-1]
                    actual_trade_date = pd.to_datetime(latest['æ—¥æœŸ']).strftime("%Y-%m-%d")

                    # è®¡ç®—å½“æ—¥æ¶¨å¹…ï¼ˆä»Šæ—¥æ”¶ç›˜ä»· vs æ˜¨æ—¥æ”¶ç›˜ä»·ï¼‰
                    day_close = latest['æ”¶ç›˜ä»·']
                    prev_close = last_5_days.iloc[-2]['æ”¶ç›˜ä»·'] if len(last_5_days) >= 2 else day_close
                    day_change_pct = ((day_close - prev_close) / prev_close) * 100 if prev_close > 0 else 0

                    # è®¡ç®—è¿‘5æ—¥ç´¯è®¡æ¶¨å¹…
                    first_close = last_5_days.iloc[0]['æ”¶ç›˜ä»·']
                    total_change_pct = ((day_close - first_close) / first_close) * 100

                    hot_concepts.append({
                        "trade_date": actual_trade_date,
                        "concept_name": concept_name,
                        "day_change_pct": round(day_change_pct, 2),
                        "change_pct": round(total_change_pct, 2),
                        "consecutive_days": 1,
                        "concept_strength": round(total_change_pct, 4),
                        "rank": 0,
                        "is_new_concept": len(last_5_days) < 5,
                        "first_seen_date": actual_trade_date if len(last_5_days) < 5 else (
                            datetime.strptime(actual_trade_date, "%Y-%m-%d") - timedelta(days=30)
                        ).strftime("%Y-%m-%d"),
                        "data_source": DataSource.AKSHARE_THS.value,
                    })

                    if (idx + 1) % 50 == 0:
                        logger.info(f"   å·²å¤„ç† {idx + 1}/{total} ä¸ªæ¦‚å¿µ")

                except Exception as e:
                    logger.debug(f"å¤„ç†æ¦‚å¿µå¤±è´¥: {concept_name}, {e}")
                    continue

            if not hot_concepts:
                return [], False

            # æ’åºå¹¶å– top_n
            hot_concepts.sort(key=lambda x: x['change_pct'], reverse=True)
            hot_concepts = hot_concepts[:top_n]

            for rank, c in enumerate(hot_concepts, 1):
                c['rank'] = rank

            logger.info(f"âœ… AKShare åŒèŠ±é¡º: æˆåŠŸé‡‡é›† {len(hot_concepts)} ä¸ªæ¦‚å¿µ")
            return hot_concepts, True

        except Exception as e:
            logger.warning(f"âŒ AKShare åŒèŠ±é¡ºå¤±è´¥: {e}")
            return [], False

    # ==================== æ•°æ®æº2: AKShare ä¸œæ–¹è´¢å¯Œ ====================

    def _collect_from_akshare_em(self, trade_date: str, top_n: int) -> Tuple[List[Dict], bool]:
        """
        ä» AKShare ä¸œæ–¹è´¢å¯Œæ¥å£é‡‡é›†æ•°æ®

        Returns:
            (æ•°æ®åˆ—è¡¨, æ˜¯å¦æˆåŠŸ)
        """
        logger.info("ğŸ”„ å°è¯•æ•°æ®æº: AKShare ä¸œæ–¹è´¢å¯Œ...")

        try:
            # è·å–æ¦‚å¿µæ¿å—åˆ—è¡¨ï¼ˆåŒ…å«å®æ—¶æ¶¨è·Œå¹…ï¼‰
            concepts_df = ak.stock_board_concept_name_em()

            if concepts_df is None or concepts_df.empty:
                logger.warning("AKShare ä¸œæ–¹è´¢å¯Œ: æ¦‚å¿µæ¿å—åˆ—è¡¨ä¸ºç©º")
                return [], False

            logger.info(f"   è·å–åˆ° {len(concepts_df)} ä¸ªæ¦‚å¿µæ¿å—")

            # ä¸œæ–¹è´¢å¯Œæ¥å£ç›´æ¥è¿”å›å½“æ—¥æ¶¨è·Œå¹…
            # åˆ—å: ['æ’å', 'æ¿å—åç§°', 'æ¿å—ä»£ç ', 'æœ€æ–°ä»·', 'æ¶¨è·Œé¢', 'æ¶¨è·Œå¹…', ...]
            hot_concepts = []

            for idx, row in concepts_df.iterrows():
                try:
                    concept_name = str(row.get('æ¿å—åç§°', ''))
                    change_pct = float(row.get('æ¶¨è·Œå¹…', 0))

                    if not concept_name:
                        continue

                    hot_concepts.append({
                        "trade_date": trade_date,
                        "concept_name": concept_name,
                        "day_change_pct": round(change_pct, 2),
                        "change_pct": round(change_pct, 2),  # ä¸œæ–¹è´¢å¯Œåªæœ‰å½“æ—¥æ•°æ®
                        "consecutive_days": 1,
                        "concept_strength": round(change_pct, 4),
                        "rank": 0,
                        "is_new_concept": False,
                        "first_seen_date": (
                            datetime.strptime(trade_date, "%Y-%m-%d") - timedelta(days=30)
                        ).strftime("%Y-%m-%d"),
                        "data_source": DataSource.AKSHARE_EM.value,
                    })

                except Exception as e:
                    logger.debug(f"å¤„ç†æ¦‚å¿µå¤±è´¥: {e}")
                    continue

            if not hot_concepts:
                return [], False

            # æ’åºå¹¶å– top_n
            hot_concepts.sort(key=lambda x: x['change_pct'], reverse=True)
            hot_concepts = hot_concepts[:top_n]

            for rank, c in enumerate(hot_concepts, 1):
                c['rank'] = rank

            logger.info(f"âœ… AKShare ä¸œæ–¹è´¢å¯Œ: æˆåŠŸé‡‡é›† {len(hot_concepts)} ä¸ªæ¦‚å¿µ")
            return hot_concepts, True

        except Exception as e:
            logger.warning(f"âŒ AKShare ä¸œæ–¹è´¢å¯Œå¤±è´¥: {e}")
            return [], False

    # ==================== æ•°æ®æº3: Tushare ====================

    def _collect_from_tushare(self, trade_date: str, top_n: int) -> Tuple[List[Dict], bool]:
        """
        ä» Tushare åŒèŠ±é¡ºæ¿å—æ—¥è¡Œæƒ…æ¥å£é‡‡é›†æ•°æ®ï¼ˆä¼˜å…ˆæ•°æ®æºï¼‰

        æ’åºé€»è¾‘: æŒ‰å½“æ—¥æ¶¨è·Œå¹…(pct_change)é™åºæ’åºï¼Œå–å‰ top_n å
        ä¼˜åŠ¿: è¿”å›ts_codeï¼Œåç»­è®¡ç®—æ¶¨åœæ•°å’Œé¾™å¤´è‚¡æ— éœ€åç§°åŒ¹é…ï¼Œè¦†ç›–ç‡100%

        Returns:
            (æ•°æ®åˆ—è¡¨, æ˜¯å¦æˆåŠŸ)
        """
        logger.info("ğŸ”„ å°è¯•æ•°æ®æº: Tushareï¼ˆé«˜çº§è´¦å·ï¼Œä¼˜å…ˆï¼‰...")

        if self.tushare_pro is None:
            logger.warning("âŒ Tushare: API æœªåˆå§‹åŒ–")
            return [], False

        try:
            # è·å–åŒèŠ±é¡ºæ¦‚å¿µæ¿å—åˆ—è¡¨
            time.sleep(0.3)  # é¿å…é¢‘ç‡é™åˆ¶
            index_df = self.tushare_pro.ths_index()
            concept_list = index_df[index_df['type'] == 'N']

            if concept_list.empty:
                logger.warning("Tushare: æ¦‚å¿µæ¿å—åˆ—è¡¨ä¸ºç©º")
                return [], False

            logger.info(f"   è·å–åˆ° {len(concept_list)} ä¸ªæ¦‚å¿µæ¿å—")

            # è·å–æŒ‡å®šæ—¥æœŸçš„æ¿å—æ—¥è¡Œæƒ…ï¼ˆå½“æ—¥æ•°æ®ï¼‰
            date_str = trade_date.replace("-", "")
            time.sleep(0.3)  # é¿å…é¢‘ç‡é™åˆ¶
            daily_df = self.tushare_pro.ths_daily(trade_date=date_str)

            if daily_df is None or daily_df.empty:
                logger.warning(f"Tushare: {trade_date} æ— æ¿å—æ—¥è¡Œæƒ…æ•°æ®")
                return [], False

            logger.info(f"   è·å–åˆ° {len(daily_df)} æ¡å½“æ—¥è¡Œæƒ…")

            # åˆå¹¶æ•°æ®ï¼Œåªä¿ç•™æ¦‚å¿µæ¿å—
            concept_codes = set(concept_list['ts_code'].tolist())
            concept_daily = daily_df[daily_df['ts_code'].isin(concept_codes)].copy()

            if concept_daily.empty:
                logger.warning("Tushare: æ— æ¦‚å¿µæ¿å—æ—¥è¡Œæƒ…æ•°æ®")
                return [], False

            # åˆå¹¶æ¦‚å¿µåç§°
            concept_daily = concept_daily.merge(
                concept_list[['ts_code', 'name']],
                on='ts_code',
                how='left'
            )

            # è®¡ç®—5æ—¥æ¶¨å¹…
            logger.info("   è®¡ç®—æ¦‚å¿µ5æ—¥æ¶¨å¹…...")
            change_5d_df = self._calculate_5day_change_tushare(concept_daily, trade_date)

            if change_5d_df is not None and not change_5d_df.empty:
                # åˆå¹¶5æ—¥æ¶¨å¹…æ•°æ®
                concept_daily = concept_daily.merge(
                    change_5d_df[['ts_code', 'change_5d']],
                    on='ts_code',
                    how='left'
                )
                # æŒ‰5æ—¥æ¶¨å¹…é™åºæ’åº
                concept_daily = concept_daily.sort_values('change_5d', ascending=False, na_position='last')
                logger.info(f"   âœ… æŒ‰5æ—¥æ¶¨å¹…æ’åº")
            else:
                # å¦‚æœ5æ—¥æ¶¨å¹…è®¡ç®—å¤±è´¥ï¼Œfallbackåˆ°å½“æ—¥æ¶¨å¹…
                logger.warning("   âš ï¸ 5æ—¥æ¶¨å¹…è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨å½“æ—¥æ¶¨å¹…æ’åº")
                concept_daily['change_5d'] = concept_daily['pct_change']
                concept_daily = concept_daily.sort_values('pct_change', ascending=False)

            hot_concepts = []
            for rank, (_, row) in enumerate(concept_daily.head(top_n).iterrows(), 1):
                change_5d = row.get('change_5d', row['pct_change'])
                hot_concepts.append({
                    "trade_date": trade_date,
                    "concept_name": row['name'],
                    "concept_code": row['ts_code'],  # âœ¨ æ·»åŠ  ts_codeï¼Œé¿å…åç»­åç§°åŒ¹é…
                    "day_change_pct": round(float(row['pct_change']), 2),
                    "change_pct": round(float(change_5d), 2),  # 5æ—¥æ¶¨å¹…
                    "consecutive_days": 1,
                    "concept_strength": round(float(change_5d), 4),
                    "rank": rank,
                    "is_new_concept": False,
                    "first_seen_date": (
                        datetime.strptime(trade_date, "%Y-%m-%d") - timedelta(days=30)
                    ).strftime("%Y-%m-%d"),
                    "data_source": DataSource.TUSHARE.value,
                })

            logger.info(f"âœ… Tushare: æˆåŠŸé‡‡é›† {len(hot_concepts)} ä¸ªæ¦‚å¿µï¼ˆæŒ‰5æ—¥æ¶¨å¹…æ’åºï¼Œå«ts_codeï¼‰")
            return hot_concepts, True

        except Exception as e:
            error_msg = str(e)
            # æ£€æŸ¥æ˜¯å¦æ˜¯é™é€Ÿé”™è¯¯
            if "é¢‘ç¹" in error_msg or "10ç§’" in error_msg or "é™åˆ¶" in error_msg:
                logger.error(f"ğŸš« Tushare è¢«é™é€Ÿ: {error_msg}")
                logger.error("â° è¯·ç­‰å¾…åé‡è¯•ï¼Œæˆ–ç¨åå†é‡‡é›†æ•°æ®")
            else:
                logger.error(f"âŒ Tushare å¤±è´¥: {error_msg}")
            return [], False

    def _calculate_5day_change_tushare(self, concept_daily: pd.DataFrame, trade_date: str) -> pd.DataFrame:
        """
        è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„è¿‘5æ—¥ç´¯è®¡æ¶¨å¹…

        ä¼˜åŒ–ç­–ç•¥ï¼š
        1. å…ˆæ‰¹é‡æŸ¥è¯¢æ‰€æœ‰æ¦‚å¿µçš„å†å²æ•°æ®
        2. å¯¹äºæ•°æ®ä¸è¶³5å¤©çš„æ¦‚å¿µï¼Œå•ç‹¬æŸ¥è¯¢è¡¥å……ï¼ˆé™ä½APIè°ƒç”¨æ¬¡æ•°ï¼‰
        3. åªä½¿ç”¨æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®è®¡ç®—æ¶¨å¹…

        Args:
            concept_daily: å½“æ—¥æ¦‚å¿µè¡Œæƒ…æ•°æ®
            trade_date: äº¤æ˜“æ—¥æœŸ

        Returns:
            åŒ…å« ts_code å’Œ change_5d çš„ DataFrame
        """
        try:
            # è·å–è¿‘æœŸäº¤æ˜“æ—¥çš„æ•°æ®ï¼ˆè€ƒè™‘å‘¨æœ«å’ŒèŠ‚å‡æ—¥ï¼Œå›æº¯15å¤©ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®ï¼‰
            date_obj = datetime.strptime(trade_date, "%Y-%m-%d")
            start_date = (date_obj - timedelta(days=15)).strftime("%Y%m%d")
            end_date = trade_date.replace("-", "")

            # æ­¥éª¤1: æ‰¹é‡è·å–å†å²è¡Œæƒ…
            logger.debug(f"   æ‰¹é‡æŸ¥è¯¢å†å²è¡Œæƒ…: {start_date} åˆ° {end_date}")
            history_df = self.tushare_pro.ths_daily(
                start_date=start_date,
                end_date=end_date
            )

            if history_df is None or history_df.empty:
                logger.warning("   æ— æ³•è·å–å†å²è¡Œæƒ…ï¼Œä½¿ç”¨å½“æ—¥æ¶¨å¹…")
                return pd.DataFrame(columns=['ts_code', 'change_5d'])

            # æŒ‰æ¦‚å¿µä»£ç å’Œæ—¥æœŸæ’åº
            history_df = history_df.sort_values(['ts_code', 'trade_date'])

            # ç»Ÿè®¡å†å²æ•°æ®
            unique_dates = history_df['trade_date'].unique()
            logger.debug(f"   æ‰¹é‡æŸ¥è¯¢: å…± {len(history_df)} æ¡ï¼Œè¦†ç›– {len(unique_dates)} ä¸ªäº¤æ˜“æ—¥")

            # æ­¥éª¤2: æ£€æŸ¥å“ªäº›æ¦‚å¿µæ•°æ®ä¸è¶³5å¤©ï¼Œéœ€è¦å•ç‹¬è¡¥å……
            concepts_need_è¡¥å…… = []
            for ts_code in concept_daily['ts_code'].unique():
                code_data = history_df[history_df['ts_code'] == ts_code]
                if len(code_data) < 5:
                    concepts_need_è¡¥å…….append(ts_code)

            # æ­¥éª¤3: å¯¹æ•°æ®ä¸è¶³çš„æ¦‚å¿µå•ç‹¬æŸ¥è¯¢
            if concepts_need_è¡¥å……:
                logger.info(f"   å‘ç° {len(concepts_need_è¡¥å……)} ä¸ªæ¦‚å¿µæ•°æ®ä¸è¶³5å¤©ï¼Œå¼€å§‹å•ç‹¬æŸ¥è¯¢...")
                è¡¥å……_count = 0

                for ts_code in concepts_need_è¡¥å……:
                    try:
                        time.sleep(0.1)  # é¿å…é¢‘ç‡é™åˆ¶
                        single_df = self.tushare_pro.ths_daily(
                            ts_code=ts_code,
                            start_date=start_date,
                            end_date=end_date
                        )

                        if single_df is not None and not single_df.empty:
                            # ç§»é™¤è¯¥æ¦‚å¿µçš„æ—§æ•°æ®
                            history_df = history_df[history_df['ts_code'] != ts_code]
                            # æ·»åŠ æ–°æ•°æ®
                            history_df = pd.concat([history_df, single_df], ignore_index=True)
                            è¡¥å……_count += 1

                            if è¡¥å……_count <= 3:  # åªæ‰“å°å‰3ä¸ª
                                logger.debug(f"      {ts_code}: è¡¥å……æˆåŠŸï¼Œç°æœ‰{len(single_df)}å¤©æ•°æ®")
                    except Exception as e:
                        logger.debug(f"      {ts_code}: è¡¥å……å¤±è´¥ - {e}")

                if è¡¥å……_count > 0:
                    logger.info(f"   âœ… æˆåŠŸè¡¥å…… {è¡¥å……_count}/{len(concepts_need_è¡¥å……)} ä¸ªæ¦‚å¿µçš„å†å²æ•°æ®")
                    # é‡æ–°æ’åº
                    history_df = history_df.sort_values(['ts_code', 'trade_date'])

            # æ­¥éª¤4: è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„è¿‘5æ—¥ç´¯è®¡æ¶¨å¹…ï¼ˆåªç”¨æœ€è¿‘5å¤©ï¼‰
            results = []
            insufficient_count = 0  # ç»Ÿè®¡æ•°æ®ä¸è¶³5å¤©çš„æ•°é‡

            for i, ts_code in enumerate(concept_daily['ts_code'].unique()):
                code_data = history_df[history_df['ts_code'] == ts_code]

                # åªå–æœ€è¿‘5å¤©æ•°æ®
                if len(code_data) >= 5:
                    code_data = code_data.tail(5)  # âœ¨ å…³é”®ä¿®æ”¹ï¼šåªå–æœ€è¿‘5å¤©
                elif len(code_data) < 5 and len(code_data) >= 1:
                    insufficient_count += 1

                # è®¡ç®—æ¶¨å¹…
                if len(code_data) >= 1:
                    days = len(code_data)

                    # ä½¿ç”¨æ¶¨è·Œå¹…å¤åˆ©è®¡ç®—
                    # å…¬å¼: ((1 + r1/100) * (1 + r2/100) * ... * (1 + rn/100) - 1) * 100
                    cumulative_return = 1.0
                    for pct in code_data['pct_change'].values:
                        cumulative_return *= (1 + pct / 100)
                    change_5d = (cumulative_return - 1) * 100

                    # å‰5ä¸ªæ¦‚å¿µæ‰“å°è¯¦ç»†æ—¥å¿—
                    if i < 5:
                        date_range = f"{code_data.iloc[0]['trade_date']} åˆ° {code_data.iloc[-1]['trade_date']}"
                        logger.debug(f"   [{ts_code}] {days}å¤©æ•°æ®({date_range}), 5æ—¥æ¶¨å¹…{change_5d:.2f}%")
                else:
                    # å®Œå…¨æ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨0
                    change_5d = 0
                    if i < 5:
                        logger.debug(f"   [{ts_code}] æ— å†å²æ•°æ®")

                results.append({
                    'ts_code': ts_code,
                    'change_5d': round(change_5d, 2)
                })

            if insufficient_count > 0:
                logger.info(f"   âš ï¸ {insufficient_count} ä¸ªæ¦‚å¿µå†å²æ•°æ®ä¸è¶³5å¤©ï¼ˆä½¿ç”¨å®é™…å¤©æ•°è®¡ç®—ï¼‰")

            logger.info(f"   æˆåŠŸè®¡ç®— {len(results)} ä¸ªæ¦‚å¿µçš„è¿‘5æ—¥æ¶¨å¹…")
            return pd.DataFrame(results)

        except Exception as e:
            logger.warning(f"   è®¡ç®—è¿‘5æ—¥æ¶¨å¹…å¤±è´¥: {e}")
            return pd.DataFrame(columns=['ts_code', 'change_5d'])

    # ==================== ä¸»é‡‡é›†æ–¹æ³• ====================

    def collect_hot_concepts(self, trade_date: Optional[str] = None, top_n: int = 50) -> List[Dict]:
        """
        é‡‡é›†çƒ­é—¨æ¦‚å¿µæ¿å—æ•°æ®ï¼ˆåªä½¿ç”¨Tushareæ•°æ®æºï¼‰

        ä¼˜å…ˆä½¿ç”¨Tushareæ•°æ®æºï¼Œå¦‚æœå¤±è´¥ï¼ˆåŒ…æ‹¬é™é€Ÿï¼‰åˆ™ç›´æ¥æŠ¥é”™ï¼Œä¸è‡ªåŠ¨åˆ‡æ¢åˆ°å…¶ä»–æ•°æ®æºã€‚
        è¿™æ ·å¯ä»¥ç¡®ä¿æ¶¨åœæ•°å’Œé¾™å¤´è‚¡æ•°æ®çš„å®Œæ•´æ€§ï¼ˆéœ€è¦ts_codeï¼‰ã€‚

        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ YYYY-MM-DDï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»Šå¤©ï¼‰
            top_n: è¿”å›å‰Nä¸ªçƒ­é—¨æ¦‚å¿µ

        Returns:
            çƒ­é—¨æ¦‚å¿µæ•°æ®åˆ—è¡¨

        Raises:
            Exception: å½“Tushareæ•°æ®æºå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        if not trade_date:
            trade_date = datetime.now().strftime("%Y-%m-%d")

        logger.info(f"=" * 50)
        logger.info(f"å¼€å§‹é‡‡é›† {trade_date} çƒ­é—¨æ¦‚å¿µæ¿å—æ•°æ®...")
        logger.info(f"æ•°æ®æº: Tushareï¼ˆå”¯ä¸€æ•°æ®æºï¼‰")
        logger.info(f"=" * 50)

        # åªä½¿ç”¨Tushareæ•°æ®æº
        concepts, success = self._collect_from_tushare(trade_date, top_n)

        if not success or not concepts:
            error_msg = f"âŒ Tushareæ•°æ®æºé‡‡é›†å¤±è´¥ï¼è¯·æ£€æŸ¥æ˜¯å¦è¢«é™é€Ÿæˆ–ç½‘ç»œé—®é¢˜ã€‚"
            logger.error(error_msg)
            raise Exception(error_msg)

        # æ›´æ–°è¿ç»­ä¸Šæ¦œå¤©æ•°ï¼ˆåŸºäºæ•°æ®åº“å†å²ï¼‰
        for concept in concepts:
            concept['consecutive_days'] = self.get_consecutive_days(
                concept['concept_name'],
                concept['trade_date']
            )

        # è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„æ¶¨åœè‚¡æ•°é‡
        concepts = self._calculate_limit_up_count(concepts, trade_date)

        # è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„é¾™å¤´è‚¡
        concepts = self._calculate_leader_stock(concepts, trade_date)

        self._log_top_concepts(concepts, DataSource.TUSHARE)
        return concepts

    def _log_top_concepts(self, concepts: List[Dict], data_source: DataSource):
        """æ‰“å°é‡‡é›†ç»“æœæ‘˜è¦"""
        logger.info(f"\n{'=' * 50}")
        logger.info(f"ğŸ“Š é‡‡é›†å®Œæˆ - æ•°æ®æº: {data_source.value}")
        logger.info(f"   äº¤æ˜“æ—¥æœŸ: {concepts[0]['trade_date'] if concepts else 'N/A'}")
        logger.info(f"   æ¦‚å¿µæ•°é‡: {len(concepts)}")
        logger.info(f"\n   æ¶¨å¹…å‰5çš„æ¦‚å¿µ:")
        for c in concepts[:5]:
            logger.info(f"   [{c['rank']}] {c['concept_name']}: {c['change_pct']}%")
        logger.info(f"{'=' * 50}\n")

    # ==================== æ¶¨åœè‚¡æ•°é‡è®¡ç®— ====================

    def _get_limit_up_stocks(self, trade_date: str) -> Set[str]:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„æ¶¨åœè‚¡ä»£ç é›†åˆï¼ˆä¼˜å…ˆä»Tushareé«˜çº§è´¦å·è·å–ï¼‰

        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ YYYY-MM-DD

        Returns:
            æ¶¨åœè‚¡ä»£ç é›†åˆï¼ˆå¸¦äº¤æ˜“æ‰€åç¼€ï¼Œå¦‚ 300081.SZï¼‰
        """
        limit_up_stocks = set()

        # æ–¹æ³•1: ä¼˜å…ˆä» Tushare limit_list_ths è·å–ï¼ˆé«˜çº§è´¦å·ï¼Œæœ€å¯é ï¼‰
        if self.tushare_pro:
            try:
                logger.debug("   å°è¯•ä» Tushare limit_list_ths è·å–æ¶¨åœè‚¡æ•°æ®...")
                time.sleep(0.3)  # é¿å…é¢‘ç‡é™åˆ¶
                limit_up_df = self.tushare_pro.limit_list_ths(
                    trade_date=trade_date.replace("-", ""),
                    limit_type='æ¶¨åœæ± '
                )

                if limit_up_df is not None and not limit_up_df.empty:
                    for _, row in limit_up_df.iterrows():
                        code = str(row.get('ts_code', ''))
                        if code:
                            limit_up_stocks.add(code)

                    logger.debug(f"   âœ… Tushare è·å–åˆ° {len(limit_up_stocks)} åªæ¶¨åœè‚¡")
                    return limit_up_stocks

            except Exception as e:
                logger.debug(f"   Tushare è·å–æ¶¨åœè‚¡å¤±è´¥: {e}")

        # æ–¹æ³•2: ä» AKShare è·å–å®æ—¶æ¶¨åœæ•°æ®ï¼ˆå¤‡ç”¨ï¼‰
        try:
            logger.debug("   å°è¯•ä» AKShare è·å–æ¶¨åœè‚¡æ•°æ®...")
            # è·å–ä»Šæ—¥æ¶¨åœè‚¡
            limit_up_df = ak.stock_zt_pool_em(date=trade_date.replace("-", ""))

            if limit_up_df is not None and not limit_up_df.empty:
                for _, row in limit_up_df.iterrows():
                    code = str(row.get('ä»£ç ', ''))
                    if code:
                        # è½¬æ¢ä¸ºå¸¦äº¤æ˜“æ‰€åç¼€çš„æ ¼å¼
                        if code.startswith('6'):
                            limit_up_stocks.add(f"{code}.SH")
                        else:
                            limit_up_stocks.add(f"{code}.SZ")

                logger.debug(f"   AKShare è·å–åˆ° {len(limit_up_stocks)} åªæ¶¨åœè‚¡")
                return limit_up_stocks

        except Exception as e:
            logger.debug(f"   AKShare è·å–æ¶¨åœè‚¡å¤±è´¥: {e}")

        # æ–¹æ³•3: ä»æ•°æ®åº“è·å–ï¼ˆæœ€åå¤‡ç”¨ï¼‰
        try:
            result = self.supabase.table('limit_stocks_detail')\
                .select('stock_code')\
                .eq('trade_date', trade_date)\
                .eq('limit_type', 'limit_up')\
                .execute()

            for row in result.data:
                code = row['stock_code']
                # è½¬æ¢ä¸ºå¸¦äº¤æ˜“æ‰€åç¼€çš„æ ¼å¼
                if code.startswith('6'):
                    limit_up_stocks.add(f"{code}.SH")
                else:
                    limit_up_stocks.add(f"{code}.SZ")

            if limit_up_stocks:
                logger.debug(f"   æ•°æ®åº“è·å–åˆ° {len(limit_up_stocks)} åªæ¶¨åœè‚¡")

            return limit_up_stocks
        except Exception as e:
            logger.warning(f"è·å–æ¶¨åœè‚¡åˆ—è¡¨å¤±è´¥: {e}")
            return set()

    def _get_concept_code_mapping(self) -> Dict[str, str]:
        """
        è·å–æ¦‚å¿µåç§°åˆ°æ¦‚å¿µä»£ç çš„æ˜ å°„ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰

        Returns:
            {æ¦‚å¿µåç§°: æ¦‚å¿µä»£ç } å­—å…¸
        """
        if self.tushare_pro is None:
            return {}

        try:
            # ä½¿ç”¨ concept() æ¥å£ä»£æ›¿ ths_index()
            concept_df = self.tushare_pro.concept()

            # æ„å»ºæ˜ å°„å­—å…¸ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
            mapping = dict(zip(concept_df['name'], concept_df['code']))

            # å¢åŠ æ¨¡ç³ŠåŒ¹é…æ”¯æŒï¼šåŒå‘åŒ¹é…"æ¦‚å¿µ"åç¼€
            for name, code in list(mapping.items()):
                # æƒ…å†µ1ï¼šå¦‚æœåŸåç§°ä¸å«"æ¦‚å¿µ"ï¼Œæ·»åŠ å¸¦"æ¦‚å¿µ"çš„å˜ä½“
                # ä¾‹å¦‚: "é˜¿å°”èŒ¨æµ·é»˜" -> æ·»åŠ  "é˜¿å°”èŒ¨æµ·é»˜æ¦‚å¿µ"
                if 'æ¦‚å¿µ' not in name:
                    mapping[f"{name}æ¦‚å¿µ"] = code
                # æƒ…å†µ2ï¼šå¦‚æœåŸåç§°ä»¥"æ¦‚å¿µ"ç»“å°¾ï¼Œæ·»åŠ å»é™¤"æ¦‚å¿µ"çš„å˜ä½“
                # ä¾‹å¦‚: "å…‰çº¤æ¦‚å¿µ" -> æ·»åŠ  "å…‰çº¤"
                elif name.endswith('æ¦‚å¿µ'):
                    mapping[name[:-2]] = code

            return mapping
        except Exception as e:
            logger.warning(f"è·å–æ¦‚å¿µä»£ç æ˜ å°„å¤±è´¥: {e}")
            return {}

    def _calculate_limit_up_count(self, concepts: List[Dict], trade_date: str) -> List[Dict]:
        """
        è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„æ¶¨åœè‚¡æ•°é‡ï¼ˆä½¿ç”¨ths_memberè·å–æˆåˆ†è‚¡ï¼Œç„¶ååŒ¹é…æ¶¨åœæ± ï¼‰

        Args:
            concepts: æ¦‚å¿µæ•°æ®åˆ—è¡¨ï¼ˆå¿…é¡»åŒ…å«concept_codeå­—æ®µï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸ

        Returns:
            æ·»åŠ äº† limit_up_count å­—æ®µçš„æ¦‚å¿µæ•°æ®åˆ—è¡¨
        """
        logger.info("ğŸ“Š å¼€å§‹è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„æ¶¨åœè‚¡æ•°é‡...")

        try:
            # ä»æ•°æ®åº“è·å–æ¶¨åœè‚¡æ•°æ®ï¼ˆåªéœ€è¦ts_codeï¼‰
            result = self.supabase.table('limit_stocks_detail')\
                .select('stock_code', 'stock_name')\
                .eq('trade_date', trade_date)\
                .eq('limit_type', 'limit_up')\
                .execute()

            if not result.data:
                logger.warning("   æœªè·å–åˆ°æ¶¨åœè‚¡æ•°æ®ï¼Œè·³è¿‡æ¶¨åœæ•°è®¡ç®—")
                for concept in concepts:
                    concept['limit_up_count'] = None
                    concept['total_count'] = None
                return concepts

            # æ„å»ºæ¶¨åœè‚¡ä»£ç é›†åˆï¼ˆæ·»åŠ äº¤æ˜“æ‰€åç¼€ï¼‰
            limit_up_codes = set()
            for stock in result.data:
                code = stock['stock_code']
                # æ·»åŠ ä¸¤ç§æ ¼å¼ï¼šå¸¦åç¼€å’Œä¸å¸¦åç¼€
                limit_up_codes.add(code)
                # æ ¹æ®ä»£ç åˆ¤æ–­äº¤æ˜“æ‰€
                if code.startswith('6'):
                    limit_up_codes.add(f"{code}.SH")
                else:
                    limit_up_codes.add(f"{code}.SZ")

            logger.info(f"   ä»Šæ—¥æ¶¨åœè‚¡: {len(result.data)} åª")

            # ä¸ºæ¯ä¸ªæ¦‚å¿µè®¡ç®—æ¶¨åœè‚¡æ•°é‡ï¼ˆä½¿ç”¨ths_memberè·å–æˆåˆ†è‚¡ï¼‰
            for concept in concepts:
                concept_name = concept['concept_name']
                concept_code = concept.get('concept_code')  # ts_code

                matched_count = 0

                if concept_code and self.tushare_pro:
                    try:
                        # ä½¿ç”¨ths_memberè·å–è¯¥æ¦‚å¿µçš„æˆåˆ†è‚¡
                        time.sleep(0.1)  # é¿å…é¢‘ç‡é™åˆ¶
                        members_df = self.tushare_pro.ths_member(ts_code=concept_code)

                        if members_df is not None and not members_df.empty:
                            # è·å–æˆåˆ†è‚¡ä»£ç åˆ—è¡¨
                            member_codes = set(members_df['con_code'].tolist())

                            # è®¡ç®—äº¤é›†ï¼šæˆåˆ†è‚¡ä¸­æœ‰å¤šå°‘åœ¨æ¶¨åœæ± ä¸­
                            matched_codes = member_codes & limit_up_codes
                            matched_count = len(matched_codes)

                            logger.debug(f"   {concept_name}: æˆåˆ†è‚¡{len(member_codes)}åª, æ¶¨åœ{matched_count}åª")
                        else:
                            logger.debug(f"   {concept_name}: æ— æˆåˆ†è‚¡æ•°æ®")

                    except Exception as e:
                        logger.debug(f"   {concept_name}: è·å–æˆåˆ†è‚¡å¤±è´¥ - {e}")

                concept['limit_up_count'] = matched_count
                concept['total_count'] = None  # æš‚ä¸ç»Ÿè®¡æ€»æˆåˆ†è‚¡æ•°

            # ç»Ÿè®¡ç»“æœ
            calculated = [c for c in concepts if c.get('limit_up_count', 0) > 0]
            logger.info(f"   æˆåŠŸè®¡ç®— {len(calculated)}/{len(concepts)} ä¸ªæ¦‚å¿µçš„æ¶¨åœè‚¡æ•°é‡")

            # æ˜¾ç¤ºæ¶¨åœæ•°æœ€å¤šçš„æ¦‚å¿µ
            top_limit_up = sorted(
                [c for c in concepts if c.get('limit_up_count', 0) > 0],
                key=lambda x: x['limit_up_count'],
                reverse=True
            )[:5]
            if top_limit_up:
                logger.info("   æ¶¨åœæ•° Top 5:")
                for c in top_limit_up:
                    logger.info(f"      {c['concept_name']}: {c['limit_up_count']} åªæ¶¨åœ")

        except Exception as e:
            logger.error(f"   è®¡ç®—æ¶¨åœæ•°å¤±è´¥: {e}")
            for concept in concepts:
                concept['limit_up_count'] = None
                concept['total_count'] = None

        return concepts

    def _get_limit_up_pool_data(self, trade_date: str) -> pd.DataFrame:
        """
        è·å–æ¶¨åœæ± å®Œæ•´æ•°æ®ï¼ˆåŒ…å«è¿æ¿æ•°ã€æ¶¨åœæ—¶é—´ç­‰ï¼‰
        ä¼˜å…ˆä»Tushareé«˜çº§è´¦å·è·å–ï¼Œæ•°æ®æ›´å¯é 

        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ YYYY-MM-DD

        Returns:
            æ¶¨åœæ±  DataFrameï¼ˆç»Ÿä¸€å­—æ®µæ ¼å¼ï¼‰
        """
        # æ–¹æ³•1: ä¼˜å…ˆä» Tushare limit_list_ths è·å–ï¼ˆé«˜çº§è´¦å·ï¼‰
        if self.tushare_pro:
            try:
                logger.debug("   å°è¯•ä» Tushare limit_list_ths è·å–æ¶¨åœæ± æ•°æ®...")
                time.sleep(0.3)
                limit_up_df = self.tushare_pro.limit_list_ths(
                    trade_date=trade_date.replace("-", ""),
                    limit_type='æ¶¨åœæ± '
                )

                if limit_up_df is not None and not limit_up_df.empty:
                    # å°†Tushareå­—æ®µæ˜ å°„åˆ°ç»Ÿä¸€æ ¼å¼
                    mapped_df = pd.DataFrame()

                    # ä»ts_codeæå–è‚¡ç¥¨ä»£ç ï¼ˆå»æ‰.SH/.SZåç¼€ï¼‰
                    mapped_df['ä»£ç '] = limit_up_df['ts_code'].apply(lambda x: x.split('.')[0] if pd.notna(x) else '')
                    mapped_df['åç§°'] = limit_up_df['name']
                    mapped_df['æ¶¨è·Œå¹…'] = limit_up_df['pct_chg']

                    # ä»tagå­—æ®µè§£æè¿æ¿æ•°ï¼ˆå¦‚"2å¤©2æ¿" -> 2ï¼Œ"é¦–æ¿" -> 1ï¼‰
                    def parse_continuous_days(tag):
                        if pd.isna(tag):
                            return 1
                        tag_str = str(tag)
                        if 'é¦–æ¿' in tag_str:
                            return 1
                        # åŒ¹é…"Nå¤©Næ¿"æ ¼å¼
                        import re
                        match = re.search(r'(\d+)å¤©', tag_str)
                        if match:
                            return int(match.group(1))
                        return 1

                    mapped_df['è¿æ¿æ•°'] = limit_up_df['tag'].apply(parse_continuous_days)

                    # ä½¿ç”¨limit_orderä½œä¸ºå°å•é¢å‚è€ƒï¼ˆéœ€è¦è½¬æ¢å•ä½ï¼‰
                    mapped_df['é¦–æ¬¡å°æ¿æ—¶é—´'] = '000000'  # Tushareæ²¡æœ‰æ­¤å­—æ®µï¼Œè®¾ç½®é»˜è®¤å€¼

                    # ä¿ç•™åŸå§‹ts_codeç”¨äºåŒ¹é…
                    mapped_df['ts_code'] = limit_up_df['ts_code']

                    logger.debug(f"   âœ… Tushare è·å–åˆ° {len(mapped_df)} åªæ¶¨åœè‚¡æ•°æ®")
                    return mapped_df

            except Exception as e:
                logger.debug(f"   Tushare è·å–æ¶¨åœæ± æ•°æ®å¤±è´¥: {e}")

        # æ–¹æ³•2: ä» AKShare è·å–ï¼ˆå¤‡ç”¨ï¼‰
        try:
            logger.debug("   å°è¯•ä» AKShare è·å–æ¶¨åœæ± æ•°æ®...")
            limit_up_df = ak.stock_zt_pool_em(date=trade_date.replace("-", ""))
            if limit_up_df is not None and not limit_up_df.empty:
                logger.debug(f"   AKShare è·å–åˆ° {len(limit_up_df)} åªæ¶¨åœè‚¡æ•°æ®")
                return limit_up_df
        except Exception as e:
            logger.warning(f"AKShare è·å–æ¶¨åœæ± æ•°æ®å¤±è´¥: {e}")

        return pd.DataFrame()

    def _calculate_leader_stock(self, concepts: List[Dict], trade_date: str) -> List[Dict]:
        """
        è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„é¾™å¤´è‚¡ï¼ˆä½¿ç”¨ths_memberè·å–æˆåˆ†è‚¡ï¼Œç„¶ååŒ¹é…æ¶¨åœæ± ï¼‰

        é¾™å¤´è‚¡å®šä¹‰ï¼š
        1. ä¼˜å…ˆé€‰æ‹©è¿ç»­æ¶¨åœæ¬¡æ•°æœ€å¤šçš„
        2. è‹¥è¿æ¿æ•°ç›¸åŒï¼Œä¼˜å…ˆé€‰æ‹©åˆ›ä¸šæ¿(300)/ç§‘åˆ›æ¿(688)
        3. è‹¥æ¿å—ç›¸åŒï¼Œé€‰æ‹©å½“æ—¥æ¶¨å¹…æœ€å¤§çš„
        4. è‹¥æ¶¨å¹…ä¹Ÿç›¸åŒï¼Œé€‰æ‹©é¦–æ¬¡å°æ¿æ—¶é—´æœ€æ—©çš„

        Args:
            concepts: æ¦‚å¿µæ•°æ®åˆ—è¡¨ï¼ˆå¿…é¡»åŒ…å«concept_codeå­—æ®µï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸ

        Returns:
            æ·»åŠ äº†é¾™å¤´è‚¡ä¿¡æ¯çš„æ¦‚å¿µæ•°æ®åˆ—è¡¨
        """
        logger.info("ğŸ“Š å¼€å§‹è®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„é¾™å¤´è‚¡...")

        try:
            # ä»æ•°æ®åº“è·å–æ¶¨åœè‚¡æ•°æ®ï¼ˆåŒ…å«è¿æ¿æ•°ç­‰ä¿¡æ¯ï¼‰
            result = self.supabase.table('limit_stocks_detail')\
                .select('stock_code', 'stock_name', 'continuous_days', 'change_pct', 'first_limit_time')\
                .eq('trade_date', trade_date)\
                .eq('limit_type', 'limit_up')\
                .execute()

            if not result.data:
                logger.warning("   æœªè·å–åˆ°æ¶¨åœè‚¡æ•°æ®ï¼Œè·³è¿‡é¾™å¤´è‚¡è®¡ç®—")
                for concept in concepts:
                    concept['leader_stock_code'] = None
                    concept['leader_stock_name'] = None
                    concept['leader_continuous_days'] = None
                    concept['leader_change_pct'] = None
                return concepts

            # æ„å»ºæ¶¨åœè‚¡å­—å…¸ï¼ˆkey=å¸¦åç¼€çš„ts_code, value=è‚¡ç¥¨ä¿¡æ¯ï¼‰
            limit_up_dict = {}
            for stock in result.data:
                code = stock['stock_code']
                # æ·»åŠ å¸¦åç¼€çš„æ ¼å¼
                if code.startswith('6'):
                    ts_code = f"{code}.SH"
                else:
                    ts_code = f"{code}.SZ"

                limit_up_dict[ts_code] = {
                    'code': code,
                    'name': stock['stock_name'],
                    'continuous_days': stock.get('continuous_days') or 1,
                    'change_pct': stock.get('change_pct') or 0,
                    'first_time': stock.get('first_limit_time') or '235959',
                    'is_gem': code.startswith('300') or code.startswith('688'),
                }

            logger.info(f"   æ¶¨åœæ± æ•°æ®: {len(result.data)} åªè‚¡ç¥¨")

            # ä¸ºæ¯ä¸ªæ¦‚å¿µè®¡ç®—é¾™å¤´è‚¡ï¼ˆä½¿ç”¨ths_memberè·å–æˆåˆ†è‚¡ï¼‰
            for concept in concepts:
                concept_name = concept['concept_name']
                concept_code = concept.get('concept_code')  # ts_code

                # åˆå§‹åŒ–é¾™å¤´è‚¡å­—æ®µ
                concept['leader_stock_code'] = None
                concept['leader_stock_name'] = None
                concept['leader_continuous_days'] = None
                concept['leader_change_pct'] = None

                if not concept_code or not self.tushare_pro:
                    continue

                try:
                    # ä½¿ç”¨ths_memberè·å–è¯¥æ¦‚å¿µçš„æˆåˆ†è‚¡
                    time.sleep(0.1)  # é¿å…é¢‘ç‡é™åˆ¶
                    members_df = self.tushare_pro.ths_member(ts_code=concept_code)

                    if members_df is None or members_df.empty:
                        logger.debug(f"   {concept_name}: æ— æˆåˆ†è‚¡æ•°æ®")
                        continue

                    # è·å–æˆåˆ†è‚¡ä¸­åœ¨æ¶¨åœæ± çš„è‚¡ç¥¨
                    concept_limit_up_stocks = []
                    for _, row in members_df.iterrows():
                        con_code = row['con_code']  # æ ¼å¼ï¼š000001.SZ
                        if con_code in limit_up_dict:
                            concept_limit_up_stocks.append(limit_up_dict[con_code])

                    if not concept_limit_up_stocks:
                        logger.debug(f"   {concept_name}: æˆåˆ†è‚¡ä¸­æ— æ¶¨åœè‚¡")
                        continue

                    # æ’åºæ‰¾é¾™å¤´ï¼š
                    # 1. è¿æ¿æ•°é™åº
                    # 2. åˆ›ä¸šæ¿/ç§‘åˆ›æ¿ä¼˜å…ˆ (is_gem=True ä¼˜å…ˆ)
                    # 3. æ¶¨å¹…é™åº
                    # 4. é¦–æ¬¡å°æ¿æ—¶é—´å‡åº
                    concept_limit_up_stocks.sort(
                        key=lambda x: (
                            -x['continuous_days'],  # è¿æ¿æ•°é™åº
                            not x['is_gem'],        # åˆ›ä¸šæ¿/ç§‘åˆ›æ¿ä¼˜å…ˆ (False < True, æ‰€ä»¥ not is_gem)
                            -x['change_pct'],       # æ¶¨å¹…é™åº
                            x['first_time'],        # é¦–æ¬¡å°æ¿æ—¶é—´å‡åº
                        )
                    )

                    leader = concept_limit_up_stocks[0]
                    concept['leader_stock_code'] = leader['code']
                    concept['leader_stock_name'] = leader['name']
                    concept['leader_continuous_days'] = leader['continuous_days']
                    concept['leader_change_pct'] = round(leader['change_pct'], 2)

                except Exception as e:
                    logger.debug(f"   {concept_name}: è®¡ç®—é¾™å¤´è‚¡å¤±è´¥ - {e}")

            # ç»Ÿè®¡ç»“æœ
            calculated = [c for c in concepts if c.get('leader_stock_code')]
            logger.info(f"   æˆåŠŸè®¡ç®— {len(calculated)}/{len(concepts)} ä¸ªæ¦‚å¿µçš„é¾™å¤´è‚¡")

            # æ˜¾ç¤ºéƒ¨åˆ†é¾™å¤´è‚¡
            if calculated:
                logger.info("   é¾™å¤´è‚¡ Top 5:")
                for c in calculated[:5]:
                    logger.info(f"      {c['concept_name']}: {c['leader_stock_name']}({c['leader_stock_code']}) {c['leader_continuous_days']}è¿æ¿")

        except Exception as e:
            logger.error(f"   è®¡ç®—é¾™å¤´è‚¡å¤±è´¥: {e}")
            for concept in concepts:
                concept['leader_stock_code'] = None
                concept['leader_stock_name'] = None
                concept['leader_continuous_days'] = None
                concept['leader_change_pct'] = None

        return concepts

    def get_consecutive_days(self, concept_name: str, current_date: str, lookback_days: int = 10) -> int:
        """
        è®¡ç®—æ¦‚å¿µçš„è¿ç»­ä¸Šæ¦œæ¬¡æ•°

        é€»è¾‘ï¼š
        1. æŸ¥è¯¢æœ€è¿‘ä¸€æ¬¡ä¸Šæ¦œæ—¥æœŸ
        2. å¦‚æœè·ç¦»å½“å‰æ—¥æœŸ<=3å¤©ï¼Œè®¤ä¸ºæ˜¯è¿ç»­çš„ï¼Œç»§æ‰¿ä¸Šæ¬¡çš„consecutive_dayså¹¶+1
        3. å¦‚æœ>3å¤©æˆ–æ²¡æœ‰å†å²è®°å½•ï¼Œè¿”å›1ï¼ˆé¦–æ¬¡ä¸Šæ¦œï¼‰

        Args:
            concept_name: æ¦‚å¿µåç§°
            current_date: å½“å‰æ—¥æœŸ YYYY-MM-DD
            lookback_days: å›æº¯å¤©æ•°ï¼Œé»˜è®¤10å¤©

        Returns:
            è¿ç»­ä¸Šæ¦œæ¬¡æ•°ï¼ˆåŒ…æ‹¬ä»Šå¤©ï¼‰
        """
        try:
            # å…³é”®ä¿®æ”¹ï¼šæŸ¥è¯¢å†å²æ•°æ®æ—¶ä½¿ç”¨ lt (å°äº) è€Œä¸æ˜¯ lte (å°äºç­‰äº)
            # å› ä¸ºå½“å‰æ—¥æœŸçš„æ•°æ®è¿˜æ²¡æœ‰ä¿å­˜åˆ°æ•°æ®åº“
            response = self.supabase.table("hot_concepts")\
                .select("trade_date, consecutive_days")\
                .eq("concept_name", concept_name)\
                .lt("trade_date", current_date)\
                .order("trade_date", desc=True)\
                .limit(1)\
                .execute()

            if not response.data:
                # æ²¡æœ‰å†å²è®°å½•ï¼Œä»Šå¤©æ˜¯ç¬¬ä¸€æ¬¡ä¸Šæ¦œ
                return 1

            # è·å–æœ€è¿‘ä¸€æ¬¡ä¸Šæ¦œçš„è®°å½•
            last_record = response.data[0]
            last_date = datetime.strptime(last_record['trade_date'], "%Y-%m-%d")
            current_date_obj = datetime.strptime(current_date, "%Y-%m-%d")
            days_diff = (current_date_obj - last_date).days

            # å¦‚æœè·ç¦»ä¸Šä¸€æ¬¡ä¸Šæ¦œä¸è¶…è¿‡3å¤©ï¼ˆè€ƒè™‘å‘¨æœ«ï¼‰ï¼Œåˆ™è®¤ä¸ºæ˜¯è¿ç»­çš„
            if days_diff <= 3:
                # ç»§æ‰¿ä¸Šæ¬¡çš„è¿ç»­å¤©æ•°å¹¶+1
                last_consecutive = last_record.get('consecutive_days', 1)
                return last_consecutive + 1
            else:
                # ä¸­æ–­äº†ï¼Œé‡æ–°å¼€å§‹è®¡æ•°
                return 1

        except Exception as e:
            logger.debug(f"è®¡ç®—è¿ç»­ä¸Šæ¦œæ¬¡æ•°å¤±è´¥: {concept_name}, {e}")
            return 1

    def save_to_database(self, concepts: List[Dict]) -> int:
        """
        ä¿å­˜çƒ­é—¨æ¦‚å¿µæ•°æ®åˆ° Supabase

        Args:
            concepts: æ¦‚å¿µæ¿å—æ•°æ®åˆ—è¡¨

        Returns:
            æˆåŠŸä¿å­˜çš„è®°å½•æ•°
        """
        if not concepts:
            logger.warning("æ²¡æœ‰æ¦‚å¿µæ•°æ®éœ€è¦ä¿å­˜")
            return 0

        try:
            logger.info(f"å‡†å¤‡ä¿å­˜ {len(concepts)} ä¸ªçƒ­é—¨æ¦‚å¿µæ•°æ®...")

            # ç§»é™¤ data_source å’Œ concept_code å­—æ®µï¼ˆä»…ç”¨äºå†…éƒ¨è®¡ç®—ï¼Œæ•°æ®åº“æ²¡æœ‰è¿™äº›åˆ—ï¼‰
            records = []
            for c in concepts:
                record = {k: v for k, v in c.items() if k not in ['data_source', 'concept_code']}
                records.append(record)

            response = self.supabase.table("hot_concepts").upsert(
                records, on_conflict="trade_date,concept_name"
            ).execute()

            logger.info(f"âœ… æˆåŠŸä¿å­˜ {len(records)} ä¸ªçƒ­é—¨æ¦‚å¿µæ•°æ®")
            return len(records)

        except Exception as e:
            logger.error(f"ä¿å­˜çƒ­é—¨æ¦‚å¿µæ•°æ®å¤±è´¥: {e}")
            return 0

    def collect_and_save(self, trade_date: Optional[str] = None, top_n: int = 10) -> int:
        """
        é‡‡é›†å¹¶ä¿å­˜çƒ­é—¨æ¦‚å¿µæ•°æ®

        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ YYYY-MM-DD
            top_n: ä¿å­˜å‰Nä¸ªçƒ­é—¨æ¦‚å¿µï¼ˆé»˜è®¤10ä¸ªï¼ŒæŒ‰5æ—¥æ¶¨å¹…æ’åºï¼‰

        Returns:
            æˆåŠŸä¿å­˜çš„è®°å½•æ•°
        """
        hot_concepts = self.collect_hot_concepts(trade_date, top_n)
        return self.save_to_database(hot_concepts)


# ä¾¿æ·å‡½æ•°
def collect_hot_concepts(trade_date: Optional[str] = None, top_n: int = 50) -> int:
    """é‡‡é›†çƒ­é—¨æ¦‚å¿µæ¿å—æ•°æ®"""
    collector = HotConceptsCollector()
    return collector.collect_and_save(trade_date, top_n)
