"""
å›æµ‹æœåŠ¡ï¼šä¿å­˜å’ŒæŸ¥è¯¢æº¢ä»·è¯„åˆ†å›æµ‹æ•°æ®
"""
from loguru import logger
from typing import Optional, List, Dict
from datetime import datetime, timedelta
import tushare as ts
import os

from app.utils.supabase_client import get_supabase
from app.services.premium_probability_service import PremiumProbabilityService


class BacktestService:
    """å›æµ‹æ•°æ®æœåŠ¡"""

    def __init__(self):
        self.supabase = get_supabase()
        self.premium_service = PremiumProbabilityService()

        # åˆå§‹åŒ–Tushare APIï¼ˆç”¨äºè·å–æ—¥çº¿è¡Œæƒ…ï¼‰
        token = os.getenv('TUSHARE_TOKEN')
        if token:
            self.ts_api = ts.pro_api(token)
        else:
            self.ts_api = None
            logger.warning("TUSHARE_TOKENæœªé…ç½®ï¼Œæ¬¡æ—¥æ•°æ®æŸ¥è¯¢å¯èƒ½ä¸å®Œæ•´")

    async def save_backtest_record(
        self,
        stock_code: str,
        trade_date: str,
        next_trade_date: Optional[str] = None,
        cached_market_data: Optional[Dict] = None
    ) -> bool:
        """
        ä¿å­˜å•ä¸ªè‚¡ç¥¨çš„å›æµ‹è®°å½•

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            trade_date: è¯„æµ‹æ—¥æœŸï¼ˆæ¶¨åœæ—¥ï¼‰YYYY-MM-DD
            next_trade_date: æ¬¡æ—¥äº¤æ˜“æ—¥æœŸï¼Œä¸ä¼ åˆ™è‡ªåŠ¨è®¡ç®—

        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            # 1. è®¡ç®—æº¢ä»·è¯„åˆ†ï¼ˆä½¿ç”¨ç¼“å­˜çš„å¸‚åœºæ•°æ®ï¼‰
            score_result = await self.premium_service.calculate_premium_score(
                stock_code, trade_date, cached_market_data
            )

            if not score_result:
                logger.warning(f"è‚¡ç¥¨ {stock_code} {trade_date} è¯„åˆ†å¤±è´¥")
                return False

            # 2. è·å–æ¬¡æ—¥äº¤æ˜“æ•°æ®
            if not next_trade_date:
                # è‡ªåŠ¨è®¡ç®—ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ï¼ˆç®€å•å¤„ç†ï¼Œå‡è®¾+1å¤©ï¼‰
                from datetime import datetime, timedelta
                trade_dt = datetime.strptime(trade_date, "%Y-%m-%d")
                next_dt = trade_dt + timedelta(days=1)
                next_trade_date = next_dt.strftime("%Y-%m-%d")

            next_day_data = self._get_next_day_data(stock_code, next_trade_date)

            # 3. æ„å»ºå›æµ‹è®°å½•
            record = {
                "stock_code": stock_code,
                "stock_name": score_result.stock_name,
                "trade_date": trade_date,
                "continuous_days": score_result.position_detail.continuous_days,
                "total_score": score_result.total_score,
                "premium_level": score_result.premium_level,
                "technical_score": score_result.technical_score,
                "capital_score": score_result.capital_score,
                "theme_score": score_result.theme_score,
                "position_score": score_result.position_score,
                "market_score": score_result.market_score,
            }

            # æ·»åŠ æ¬¡æ—¥æ•°æ®
            if next_day_data:
                record.update({
                    "next_trade_date": next_trade_date,
                    "next_day_change_pct": next_day_data.get("change_pct"),
                    "next_day_close_price": next_day_data.get("close_price"),
                    "is_next_day_limit_up": next_day_data.get("limit_type") == "limit_up",
                    "is_next_day_limit_down": next_day_data.get("limit_type") == "limit_down",
                    "next_day_turnover_rate": next_day_data.get("turnover_rate"),
                })

                # åˆ¤æ–­é¢„æµ‹å‡†ç¡®æ€§
                prediction_result = self._evaluate_prediction(
                    score_result.total_score,
                    next_day_data.get("change_pct")
                )
                record["prediction_result"] = prediction_result
                record["is_profitable"] = next_day_data.get("change_pct", 0) > 0

            # 4. ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆupsertï¼‰
            response = self.supabase.table("premium_score_backtest")\
                .upsert(record, on_conflict="stock_code,trade_date")\
                .execute()

            logger.info(f"âœ… ä¿å­˜å›æµ‹è®°å½•: {stock_code} {trade_date} è¯„åˆ†{score_result.total_score:.2f}")
            return True

        except Exception as e:
            logger.error(f"ä¿å­˜å›æµ‹è®°å½•å¤±è´¥: {e}", exc_info=True)
            return False

    async def batch_save_backtest(
        self,
        trade_date: str,
        next_trade_date: Optional[str] = None,
        limit: int = 50
    ) -> Dict:
        """
        æ‰¹é‡ä¿å­˜æŸå¤©æ‰€æœ‰æ¶¨åœè‚¡ç¥¨çš„å›æµ‹è®°å½•

        Args:
            trade_date: è¯„æµ‹æ—¥æœŸ YYYY-MM-DD
            next_trade_date: æ¬¡æ—¥äº¤æ˜“æ—¥æœŸ
            limit: æœ€å¤šå¤„ç†å¤šå°‘åªè‚¡ç¥¨

        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        logger.info(f"å¼€å§‹æ‰¹é‡ä¿å­˜ {trade_date} çš„å›æµ‹æ•°æ®...")

        # âš¡ æ€§èƒ½ä¼˜åŒ–ï¼šæå‰è®¡ç®—å¸‚åœºç¯å¢ƒæ•°æ®ï¼ˆæ‰€æœ‰è‚¡ç¥¨å…±äº«ï¼‰
        logger.info(f"ğŸ“Š é¢„è®¡ç®—å¸‚åœºç¯å¢ƒæ•°æ®...")
        from app.services.sentiment_service import SentimentService
        sentiment_service = SentimentService()
        market_data = await sentiment_service.get_analysis(trade_date)
        logger.info(f"âœ… å¸‚åœºç¯å¢ƒæ•°æ®å·²ç¼“å­˜")

        # è·å–å½“å¤©æ‰€æœ‰æ¶¨åœè‚¡ç¥¨
        response = self.supabase.table("limit_stocks_detail")\
            .select("stock_code, stock_name")\
            .eq("trade_date", trade_date)\
            .eq("limit_type", "limit_up")\
            .limit(limit)\
            .execute()

        stocks = response.data
        logger.info(f"æ‰¾åˆ° {len(stocks)} åªæ¶¨åœè‚¡ç¥¨")

        success_count = 0
        fail_count = 0

        for stock in stocks:
            success = await self.save_backtest_record(
                stock["stock_code"],
                trade_date,
                next_trade_date,
                cached_market_data=market_data  # å¤ç”¨å¸‚åœºæ•°æ®
            )

            if success:
                success_count += 1
            else:
                fail_count += 1

        logger.info(f"æ‰¹é‡ä¿å­˜å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")

        return {
            "total": len(stocks),
            "success": success_count,
            "fail": fail_count,
            "trade_date": trade_date
        }

    def _get_next_day_data(self, stock_code: str, next_trade_date: str) -> Optional[Dict]:
        """
        è·å–æ¬¡æ—¥äº¤æ˜“æ•°æ®

        ä¼˜å…ˆä»limit_stocks_detailè¡¨æŸ¥è¯¢ï¼ˆå¦‚æœæ¬¡æ—¥æ¶¨åœ/è·Œåœï¼‰
        å¦‚æœæŸ¥ä¸åˆ°ï¼Œåˆ™è°ƒç”¨Tushare APIè·å–æ—¥çº¿è¡Œæƒ…æ•°æ®
        """
        try:
            # æ–¹æ³•1: å…ˆä»æ¶¨åœè¡¨æŸ¥è¯¢ï¼ˆå¦‚æœæ¬¡æ—¥æ¶¨åœ/è·Œåœï¼Œè¿™é‡Œèƒ½æŸ¥åˆ°æ›´è¯¦ç»†çš„æ•°æ®ï¼‰
            response = self.supabase.table("limit_stocks_detail")\
                .select("change_pct, close_price, turnover_rate, limit_type")\
                .eq("stock_code", stock_code)\
                .eq("trade_date", next_trade_date)\
                .execute()

            if response.data and len(response.data) > 0:
                logger.debug(f"ä»æ¶¨åœè¡¨è·å– {stock_code} {next_trade_date} æ•°æ®")
                return response.data[0]

            # æ–¹æ³•2: æ¶¨åœè¡¨æŸ¥ä¸åˆ°ï¼Œè°ƒç”¨Tushare APIè·å–æ—¥çº¿è¡Œæƒ…
            if not self.ts_api:
                logger.warning(f"{stock_code} {next_trade_date} æ¶¨åœè¡¨æ— æ•°æ®ï¼Œä¸”Tushareæœªé…ç½®")
                return None

            logger.debug(f"æ¶¨åœè¡¨æ— æ•°æ®ï¼Œè°ƒç”¨Tushareè·å– {stock_code} {next_trade_date} æ—¥çº¿æ•°æ®")

            # è½¬æ¢æ—¥æœŸæ ¼å¼ï¼šYYYY-MM-DD -> YYYYMMDD
            ts_date = next_trade_date.replace('-', '')

            # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼ï¼šXXXXXX -> XXXXXX.SH/SZ
            if stock_code.startswith(('6', '900')):
                ts_code = f"{stock_code}.SH"
            elif stock_code.startswith(('0', '2', '3')):
                ts_code = f"{stock_code}.SZ"
            elif stock_code.startswith(('8', '4')):
                ts_code = f"{stock_code}.BJ"  # åŒ—äº¤æ‰€
            else:
                ts_code = f"{stock_code}.SH"  # é»˜è®¤ä¸Šäº¤æ‰€

            # è°ƒç”¨Tushare API
            df = self.ts_api.daily(
                ts_code=ts_code,
                start_date=ts_date,
                end_date=ts_date
            )

            if df is None or df.empty:
                logger.warning(f"Tushareæœªè¿”å› {stock_code} {next_trade_date} æ•°æ®ï¼ˆå¯èƒ½åœç‰Œï¼‰")
                return None

            # è§£ææ•°æ®
            row = df.iloc[0]
            change_pct = row['pct_chg']  # æ¶¨è·Œå¹…%
            close_price = row['close']
            turnover_rate = row['turnover_rate'] if 'turnover_rate' in df.columns else None

            # åˆ¤æ–­æ¶¨è·Œåœï¼ˆç®€å•åˆ¤æ–­ï¼š>=9.9%ä¸ºæ¶¨åœï¼Œ<=-9.9%ä¸ºè·Œåœï¼‰
            limit_type = None
            if change_pct >= 9.9:
                limit_type = "limit_up"
            elif change_pct <= -9.9:
                limit_type = "limit_down"

            return {
                "change_pct": change_pct,
                "close_price": close_price,
                "turnover_rate": turnover_rate,
                "limit_type": limit_type
            }

        except Exception as e:
            logger.error(f"è·å–æ¬¡æ—¥æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return None

    def _evaluate_prediction(self, score: float, next_pct: Optional[float]) -> str:
        """
        è¯„ä¼°é¢„æµ‹å‡†ç¡®æ€§

        è§„åˆ™ï¼š
        - é«˜åˆ†è‚¡ç¥¨ï¼ˆâ‰¥7åˆ†ï¼‰ï¼šæ¬¡æ—¥åº”è¯¥ä¸Šæ¶¨ â†’ ä¸Šæ¶¨ä¸ºæ­£ç¡®
        - ä½åˆ†è‚¡ç¥¨ï¼ˆ<5åˆ†ï¼‰ï¼šæ¬¡æ—¥åº”è¯¥ä¸‹è·Œæˆ–å¹³æ·¡ â†’ ä¸‹è·Œä¸ºæ­£ç¡®
        - ä¸­ç­‰è‚¡ç¥¨ï¼ˆ5-7åˆ†ï¼‰ï¼šä¸­æ€§
        """
        if next_pct is None:
            return "unknown"

        if score >= 7:
            # é«˜åˆ†è‚¡ç¥¨é¢„æœŸä¸Šæ¶¨
            return "correct" if next_pct > 0 else "wrong"
        elif score < 5:
            # ä½åˆ†è‚¡ç¥¨é¢„æœŸä¸‹è·Œ
            return "correct" if next_pct <= 0 else "wrong"
        else:
            # ä¸­ç­‰åˆ†æ•°ä¸­æ€§
            return "neutral"

    def query_backtest_results(
        self,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        min_score: Optional[float] = None,
        max_score: Optional[float] = None,
        page: int = 1,
        page_size: int = 20
    ) -> tuple[List[Dict], int]:
        """
        æŸ¥è¯¢å›æµ‹ç»“æœï¼ˆæ”¯æŒåˆ†é¡µï¼‰

        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            min_score: æœ€ä½åˆ†æ•°
            max_score: æœ€é«˜åˆ†æ•°
            page: é¡µç ï¼ˆä»1å¼€å§‹ï¼‰
            page_size: æ¯é¡µæ¡æ•°

        Returns:
            (å›æµ‹è®°å½•åˆ—è¡¨, æ€»è®°å½•æ•°)
        """
        try:
            # æ„å»ºæŸ¥è¯¢
            query = self.supabase.table("premium_score_backtest")\
                .select("*", count="exact")

            if start_date:
                query = query.gte("trade_date", start_date)
            if end_date:
                query = query.lte("trade_date", end_date)
            if min_score is not None:
                query = query.gte("total_score", min_score)
            if max_score is not None:
                query = query.lte("total_score", max_score)

            # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            query = query.order("created_at", desc=True)

            # è®¡ç®—offset
            offset = (page - 1) * page_size

            # æ‰§è¡Œåˆ†é¡µæŸ¥è¯¢
            response = query.range(offset, offset + page_size - 1).execute()

            total = response.count if hasattr(response, 'count') else len(response.data)

            return response.data, total

        except Exception as e:
            logger.error(f"æŸ¥è¯¢å›æµ‹ç»“æœå¤±è´¥: {e}")
            return [], 0

    def get_backtest_statistics(self, trade_date: Optional[str] = None) -> Dict:
        """
        è·å–å›æµ‹ç»Ÿè®¡æ•°æ®

        Args:
            trade_date: æŒ‡å®šæ—¥æœŸï¼Œä¸ä¼ åˆ™ç»Ÿè®¡æ‰€æœ‰

        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            query = self.supabase.table("premium_score_backtest").select("*")

            if trade_date:
                query = query.eq("trade_date", trade_date)

            response = query.execute()
            records = response.data

            if not records:
                return {"total": 0}

            # ç»Ÿè®¡å„ç­‰çº§è¡¨ç°
            stats = {
                "total": len(records),
                "by_level": {},
                "by_score_range": {},
                "overall": {
                    "avg_next_day_pct": 0,
                    "limit_up_count": 0,
                    "limit_up_rate": 0,
                    "profitable_count": 0,
                    "profitable_rate": 0,
                    "correct_predictions": 0,
                    "prediction_accuracy": 0
                }
            }

            # æŒ‰ç­‰çº§åˆ†ç»„
            level_groups = {}
            for record in records:
                level = record["premium_level"]
                if level not in level_groups:
                    level_groups[level] = []
                level_groups[level].append(record)

            # è®¡ç®—å„ç­‰çº§ç»Ÿè®¡
            for level, group in level_groups.items():
                valid_group = [r for r in group if r.get("next_day_change_pct") is not None]

                if len(valid_group) == 0:
                    continue

                avg_pct = sum(r["next_day_change_pct"] for r in valid_group) / len(valid_group)
                limit_up_count = sum(1 for r in valid_group if r.get("is_next_day_limit_up"))
                profitable_count = sum(1 for r in valid_group if r.get("is_profitable"))
                correct_count = sum(1 for r in valid_group if r.get("prediction_result") == "correct")

                stats["by_level"][level] = {
                    "count": len(valid_group),
                    "avg_next_day_pct": round(avg_pct, 2),
                    "limit_up_count": limit_up_count,
                    "limit_up_rate": round(limit_up_count / len(valid_group) * 100, 2),
                    "profitable_count": profitable_count,
                    "profitable_rate": round(profitable_count / len(valid_group) * 100, 2),
                    "prediction_accuracy": round(correct_count / len(valid_group) * 100, 2) if len(valid_group) > 0 else 0
                }

            # æ€»ä½“ç»Ÿè®¡
            valid_records = [r for r in records if r.get("next_day_change_pct") is not None]
            if valid_records:
                stats["overall"]["avg_next_day_pct"] = round(
                    sum(r["next_day_change_pct"] for r in valid_records) / len(valid_records), 2
                )
                stats["overall"]["limit_up_count"] = sum(1 for r in valid_records if r.get("is_next_day_limit_up"))
                stats["overall"]["limit_up_rate"] = round(
                    stats["overall"]["limit_up_count"] / len(valid_records) * 100, 2
                )
                stats["overall"]["profitable_count"] = sum(1 for r in valid_records if r.get("is_profitable"))
                stats["overall"]["profitable_rate"] = round(
                    stats["overall"]["profitable_count"] / len(valid_records) * 100, 2
                )

                correct_count = sum(1 for r in valid_records if r.get("prediction_result") == "correct")
                stats["overall"]["correct_predictions"] = correct_count
                stats["overall"]["prediction_accuracy"] = round(
                    correct_count / len(valid_records) * 100, 2
                )

            return stats

        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
            return {"total": 0, "error": str(e)}

    def delete_backtest_records(self, record_ids: List[int]) -> int:
        """
        æ‰¹é‡åˆ é™¤å›æµ‹è®°å½•

        Args:
            record_ids: è®°å½•IDåˆ—è¡¨

        Returns:
            åˆ é™¤çš„è®°å½•æ•°
        """
        try:
            if not record_ids:
                return 0

            # Supabase æ‰¹é‡åˆ é™¤
            response = self.supabase.table("premium_score_backtest")\
                .delete()\
                .in_("id", record_ids)\
                .execute()

            deleted_count = len(response.data) if response.data else 0
            logger.info(f"æˆåŠŸåˆ é™¤ {deleted_count} æ¡å›æµ‹è®°å½•")

            return deleted_count

        except Exception as e:
            logger.error(f"åˆ é™¤å›æµ‹è®°å½•å¤±è´¥: {e}")
            raise
