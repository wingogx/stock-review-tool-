"""
æ‰‹åŠ¨è¡¥é‡‡é›†2025-12-11æ¶¨åœè‚¡ç¥¨åœ¨12æœˆ12æ—¥çš„è¡¨ç°
"""
import sys
import os
sys.path.append(os.path.dirname(__file__))

from dotenv import load_dotenv
load_dotenv()

from loguru import logger
from app.services.collectors.limit_stocks_collector import LimitStocksCollector
from app.utils.supabase_client import get_supabase

def main():
    collector = LimitStocksCollector()
    supabase = get_supabase()

    trade_date = "2025-12-12"
    previous_date = "2025-12-11"

    logger.info(f"å¼€å§‹è¡¥é‡‡é›† {previous_date} æ¶¨åœè‚¡ç¥¨åœ¨ {trade_date} çš„è¡¨ç°...")

    # 1. æŸ¥è¯¢å‰ä¸€äº¤æ˜“æ—¥æ¶¨åœçš„è‚¡ç¥¨
    yesterday_stocks = collector._get_previous_day_limit_up_stocks(previous_date)
    logger.info(f"âœ… {previous_date} æ¶¨åœè‚¡ç¥¨: {len(yesterday_stocks)} åª")

    # 2. æŸ¥è¯¢ä»Šæ—¥å·²æœ‰æ•°æ®çš„è‚¡ç¥¨
    response_today = supabase.table("limit_stocks_detail")\
        .select("stock_code")\
        .eq("trade_date", trade_date)\
        .execute()

    existing_codes = set([r["stock_code"] for r in response_today.data])
    logger.info(f"âœ… {trade_date} å·²æœ‰æ•°æ®: {len(existing_codes)} åª")

    # 3. æ‰¾å‡ºç¼ºå¤±çš„è‚¡ç¥¨
    all_codes = set([s["stock_code"] for s in yesterday_stocks])
    missing_codes = all_codes - existing_codes

    logger.info(f"âš ï¸  ç¼ºå¤±æ•°æ®: {len(missing_codes)} åª")
    logger.info(f"   ç¼ºå¤±è‚¡ç¥¨: {list(missing_codes)}")

    if not missing_codes:
        logger.info("âœ… æ‰€æœ‰è‚¡ç¥¨æ•°æ®å·²å®Œæ•´ï¼Œæ— éœ€è¡¥é‡‡é›†")
        return

    # 4. è¡¥é‡‡é›†ç¼ºå¤±çš„è‚¡ç¥¨
    missing_stocks = [s for s in yesterday_stocks if s["stock_code"] in missing_codes]
    stock_codes = [s["stock_code"] for s in missing_stocks]
    stock_name_map = {s["stock_code"]: s["stock_name"] for s in missing_stocks}

    logger.info(f"\nå¼€å§‹é‡‡é›†è¿™ {len(stock_codes)} åªè‚¡ç¥¨çš„æ—¥çº¿æ•°æ®...")
    daily_df = collector._collect_stocks_daily_data(stock_codes, trade_date)

    if daily_df.empty:
        logger.error("âŒ æœªè·å–åˆ°æ—¥çº¿æ•°æ®")
        return

    logger.info(f"âœ… æˆåŠŸè·å– {len(daily_df)} åªè‚¡ç¥¨çš„æ—¥çº¿æ•°æ®")

    # 5. å¤„ç†å¹¶ä¿å­˜æ•°æ®
    performance_records = collector._process_daily_data(daily_df, trade_date, stock_name_map)

    if performance_records:
        saved_count = collector.save_to_database(performance_records)
        logger.info(f"\nğŸ‰ æˆåŠŸä¿å­˜ {saved_count} æ¡è®°å½•")

        # æ˜¾ç¤ºéƒ¨åˆ†ç»“æœ
        logger.info("\né‡‡é›†ç»“æœç¤ºä¾‹:")
        for r in performance_records[:10]:
            logger.info(
                f"  {r['stock_code']} {r['stock_name']}: "
                f"{r['change_pct']:.2f}% (limit_type={r['limit_type']})"
            )
    else:
        logger.warning("âš ï¸  æ²¡æœ‰æœ‰æ•ˆè®°å½•")

if __name__ == "__main__":
    main()
